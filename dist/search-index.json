[{"url":"index.html","title":"Fogsift","description":"Submit your problem to the FogSift queue. Up to an hour of focus plus a PDF write-up and video response. Video may or may not be published.","headings":["Clear answers to good questions üè° üå§ üî≠ Something taking too long with your time? We work on everything from Real Estate to Dungeons & Dragons. $20. Report + video response. Leave unchecked if human Join the Queue ($20) See the Queue By submitting, you agree to our Terms . Submissions may be used for content. Request anonymization if needed. HOW IT WORKS 01 Submit Describe your problem + pay $20 on Ko-fi. 02 Review Each day, we review submissions and choose what to work on next. 03 Work Up to an hour of focused work on your submission. 04 Deliver You receive a PDF write-up and a video response. 05 Next Steps You'll get one of three outcomes. If it's a fit, I'll invite you to go deeper on my terms. WHY THIS WORKS 01 Skin in the Game $20 keeps submissions real and funds production. 02 Work You Can Inspect Sessions are recorded and may be published. Judge the thinking, not the credentials. 03 Time-Boxed Focus One hour of undivided attention. No meetings. No Slack. 04 Clear Outcomes You leave with either a fix, a roadmap, or a referral. EXAMPLES FROM THE QUEUE Representative examples of the kinds of problems the queue is built for. Names anonymized. Operations \"Our inventory counts never match.\" Two systems were rounding differently. Align the rules, fix the feed, move on. Outcome: Diagnosis + fix Technical \"Our app crashes every Tuesday.\" Weekly cron job collided with peak traffic. Move it to 3 AM and the problem disappears. Outcome: Root cause + fix Strategy \"Build it or buy it?\" Mapped hidden costs and timing risk. Recommendation: buy now, migrate later. Outcome: Decision framework Marketing \"Signups stalled.\" Walked the funnel live. Fixed the top three friction points during the session. Outcome: Funnel fixes + roadmap WHO IS FOGSIFT Christopher Tavolazzi Expert Researcher Software developer. Former realtor, brewery tour guide, journalist, author, and Eagle Scout. He's lived in a van across America's national parks and played music on three continents. Whatever you're stuck on, he can probably find someone who knows how to fix it. If it's a fit, he'll invite you to go deeper on his terms. WHAT CLIENTS SAY \"We spent six months treating symptoms before FogSift traced the problem to its source. One conversation changed our entire approach.\" Operations Director Manufacturing Company \"Clear, direct, no fluff. Christopher asked the questions we should have been asking ourselves. Worth every dollar.\" Founder &amp; CEO Tech Startup \"The diagnostic process revealed three bottlenecks we'd been ignoring for years. Fixed them in a month.\" VP of Strategy Professional Services Firm \"I didn't think a single session could do this much. The write-up alone was worth ten times the price.\" Small Business Owner Retail &amp; E-commerce \"We spent six months treating symptoms before FogSift traced the problem to its source. One conversation changed our entire approach.\" Operations Director Manufacturing Company \"Clear, direct, no fluff. Christopher asked the questions we should have been asking ourselves. Worth every dollar.\" Founder &amp; CEO Tech Startup \"The diagnostic process revealed three bottlenecks we'd been ignoring for years. Fixed them in a month.\" VP of Strategy Professional Services Firm \"I didn't think a single session could do this much. The write-up alone was worth ten times the price.\" Small Business Owner Retail &amp; E-commerce 15+ Engagements 100% Satisfaction 8+ Industries THE DEAL ENTRY Field Guide PDF $5 \"How to Talk to AI\": a practical guide to getting useful answers from AI tools. PDF only. No session or queue access. Instant download. Share freely. Get the PDF THE SWEET SPOT Focus Session $20 A full-on research squad (me + AI + friends + network) focused on your submission for up to an hour. Worth way more than $20, kept low so anyone can access it. Your $20 adds your problem to the queue . You receive a PDF write-up and a video response. We may or may not publish a video. One-time fee per submission (not a subscription). If you're not picked right away, you stay in the queue. Your submission may be used for other purposes, including marketing. Request anonymization if needed. Maybe we solve it. Maybe we don't. Either way, you walk away with something. ‚ö° Limited to 10 slots/week Join the Queue PREMIUM Deep Dive $500 Private, scheduled session. Full documentation. Follow‚Äëup included. 100% confidential. Best for complex problems. Book a Deep Dive COMMON CONCERNS \"What if you can't solve it?\" Then you still get the PDF write-up and video response, plus a narrower problem statement or referral. \"Is my problem too big?\" One hour is for momentum. You'll leave with clarity and next steps, even if the full fix takes longer. \"Why charge $20?\" It funds production, keeps submissions real, and keeps the price low enough for anyone to access. \"Will my submission be public?\" We may or may not publish a video. Your submission may be used for other purposes, including marketing. Request anonymization if needed. Ready to put your idea in the queue?"],"content":"Gold Star Clear answers to good questions üè° üå§ üî≠ Something taking too long with your time? We work on everything from Real Estate to Dungeons & Dragons. $20. Report + video response. Leave unchecked if human Join the Queue ($20) See the Queue By submitting, you agree to our Terms . Submissions may be used for content. Request anonymization if needed. HOW IT WORKS 01 Submit Describe your problem + pay $20 on Ko-fi. 02 Review Each day, we review submissions and choose what to work on next. 03 Wo","category":"Home"},{"url":"about.html","title":"About","description":"Meet Christopher Tavolazzi - the expert researcher behind Fogsift. Software developer, former realtor, journalist, author, and Eagle Scout.","headings":["WHO IS FOGSIFT Christopher Tavolazzi Founder &amp; FogSift Operator Software developer. Former realtor, brewery tour guide, journalist, author, and Eagle Scout. He's lived in a van across America's national parks and played music on three continents. Whatever you're stuck on, he can probably find someone who knows how to fix it. WHAT CLIENTS SAY \"We spent six months treating symptoms before FogSift traced the problem to its source. One conversation changed our entire approach.\" Operations Director Manufacturing Company \"Clear, direct, no fluff. Christopher asked the questions we should have been asking ourselves. Worth every dollar.\" Founder &amp; CEO Tech Startup \"Most consultants tell you what you want to hear. This one told us what we needed to hear. Saved us from a costly mistake.\" Project Manager Construction Firm VOLUNTEER WITH US FogSift is growing. We're looking for volunteers who want to help research, write, produce videos, or contribute in ways we haven't thought of yet. No formal requirements. Just curiosity and follow-through. Get in Touch Email christopher@fogsift.com Ready to get unstuck?"],"content":"WHO IS FOGSIFT Christopher Tavolazzi Founder &amp; FogSift Operator Software developer. Former realtor, brewery tour guide, journalist, author, and Eagle Scout. He's lived in a van across America's national parks and played music on three continents. Whatever you're stuck on, he can probably find someone who knows how to fix it. WHAT CLIENTS SAY \"We spent six months treating symptoms before FogSift traced the problem to its source. One conversation changed our entire approach.\" Operations Direct","category":"About"},{"url":"offers.html","title":"Offers","description":"FogSift offers: Free triage calls, $5 Field Guide, $20 Queue Response, $500 Deep Dive, or custom engagement. Pick what works for you.","headings":["CHOOSE YOUR PATH No subscriptions. No hidden fees. Pick what works for you. The Call FREE 15-30 minute triage. Understand your situation. No pitch, no pressure. Book a Call STARTER Field Guide PDF $5 Practical guide to getting useful answers from AI tools. Instant download. Get the PDF MOST POPULAR Queue Response $20 Submit your request. Get a report + video response (30-90 sec) with our findings. Join the Queue PRIVATE Deep Dive $500 Private scheduled session. Full documentation. Follow-up included. 100% confidential. Book a Deep Dive BOUTIQUE Custom Engagement By Quote One client per work term. Extended collaboration on your terms. Limited availability. Inquire WHAT'S INCLUDED The Call Free A quick 15-30 minute conversation to understand your situation. No strings attached. Video call or phone, your preference Honest assessment of your situation No sales pitch, just conversation Field Guide PDF $5 A practical guide to getting genuinely useful answers from AI tools. Not hype, not theory. Instant download after purchase Real prompting strategies Common pitfalls to avoid Get the Field Guide &rarr; Queue Response $20 Our main offer. Submit your request, and we'll research, analyze, and respond with a report and short video. Written report with findings and recommendations Video response (30-90 seconds) Up to 3 requests processed daily May become a YouTube video at our discretion Good for: Technical questions, research requests, second opinions, feasibility checks. Learn more about the Queue &rarr; Deep Dive $500 For situations that need real attention. Private, scheduled, 100% confidential. Scheduled 1-2 hour working session Full written documentation One follow-up session included Direct access via email/chat for 2 weeks Good for: Sensitive business problems, strategic decisions, architecture review. Custom Engagement By Quote Boutique consulting. One client per work term. Focused attention without splitting priorities. One client at a time (no competing priorities) Flexible structure based on your needs All deliverables and IP belong to you Good for: Ongoing projects, team augmentation, building something together over time. COMPARE OPTIONS Feature Call Guide Queue Deep Dive Custom Price Free $5 $20 $500 Quote Written deliverable &mdash; PDF Report Full docs Custom Video response &mdash; &mdash; 30-90s Optional Optional Live interaction 15-30m &mdash; &mdash; 1-2h Ongoing Confidential Yes N/A Public* Yes Yes Follow-up included &mdash; &mdash; &mdash; Yes Yes *Queue responses are public by default so others can learn. Privacy requests respected where possible. COMMON QUESTIONS Which offer should I choose? Not sure what you need? Book a free call first. We'll figure it out together. Have a specific question? The $20 Queue Response is probably right. Need something confidential? Deep Dive or Custom Engagement. Just curious about AI? Grab the $5 Field Guide. Why is the Queue so cheap? We'd rather help 100 people at accessible prices than 5 people at premium rates. The queue also becomes content for the YouTube channel, so everyone benefits&mdash;you get help, others learn from watching. What if I'm not satisfied? For the Queue: if your request hasn't been processed yet, request a refund through Ko-fi anytime. No questions asked. For Deep Dive and Custom: if you don't find value, we'll make it right. We'd rather have a good relationship than keep your money. Do you do ongoing retainers? That's what the Custom Engagement is for. We take on one client per work term to give focused attention. Limited availability&mdash;reach out to discuss. Can I upgrade from Queue to Deep Dive? Yes. If your Queue submission reveals something that needs more attention, we can discuss upgrading. Your $20 counts toward the Deep Dive fee. What kinds of problems do you work on? Technical questions, research requests, feasibility checks, process problems, \"should I build or buy\" decisions, debugging, architecture review, and more. If you're stuck on something concrete, we can probably help. We don't do: financial/investment advice, legal advice, interpersonal disputes, or anything illegal/unethical. Not sure where to start?"],"content":"CHOOSE YOUR PATH No subscriptions. No hidden fees. Pick what works for you. The Call FREE 15-30 minute triage. Understand your situation. No pitch, no pressure. Book a Call STARTER Field Guide PDF $5 Practical guide to getting useful answers from AI tools. Instant download. Get the PDF MOST POPULAR Queue Response $20 Submit your request. Get a report + video response (30-90 sec) with our findings. Join the Queue PRIVATE Deep Dive $500 Private scheduled session. Full documentation. Follow-up incl","category":"Offers"},{"url":"queue.html","title":"The Queue","description":"Submit your request for $20. Get a report and video response. Watch your request move through the FogSift queue.","headings":["Sifting the Queue Submit your request. Get a response. Join the Queue ($20) By joining, you agree to our Terms & Conditions . LIVE QUEUE - Pending - In Progress - Completed All Pending In Progress Completed Loading queue... Updated just now ¬∑ Refresh HOW IT WORKS 1 Submit Pay $20 on Ko-fi and describe your request in the message. 2 Queue Your request appears here. We pick up to 3 daily. 3 Research We dig into finding research, analysis, and data. 4 Respond You get a report + video response with our findings. What to Include in Your Submission When you submit on Ko-fi, include in your message: The request : What do you need help with? Be specific. Context : What have you tried? What's the situation? Goal : What would \"solved\" look like? Contact info : Email where we can send your report Example submission: \"My Raspberry Pi project keeps crashing after ~2 hours of runtime. I've checked the power supply and it seems fine. Running a Python script that reads sensor data. Want it to run 24/7 reliably. Email: me@example.com\" What You Get &#x1F4CB; Report Findings, recommendations, and next steps &#x1F3AC; Video Response 30-90 seconds summarizing our findings We may or may not choose to make a YouTube video about your request at our discretion. FAQ Will my request be public? By default, yes, so others can learn. We'll respect privacy requests where possible, but we can't guarantee anything submitted online stays private. How long until my request gets picked? Could be days, could be weeks. We aim for up to 3 per day. If you need something faster, consider a Deep Dive . Can I get a refund? Yes. Request a refund through Ko-fi if we haven't addressed your request yet. No hard feelings. See full FAQ &rarr; Ready to submit a request?"],"content":"The Queue Sifting the Queue Submit your request. Get a response. Join the Queue ($20) By joining, you agree to our Terms & Conditions . LIVE QUEUE - Pending - In Progress - Completed All Pending In Progress Completed Loading queue... Updated just now ¬∑ Refresh HOW IT WORKS 1 Submit Pay $20 on Ko-fi and describe your request in the message. 2 Queue Your request appears here. We pick up to 3 daily. 3 Research We dig into finding research, analysis, and data. 4 Respond You get a report + video resp","category":"Queue"},{"url":"faq.html","title":"FAQ","description":"Frequently asked questions about FogSift's Focus Session. What $20 gets you, how the queue works, refunds, and more.","headings":["FAQ Frequently Asked Questions The Queue What does $20 get me? Your $20 buys you: A position in the queue Up to 1 hour of focused attention on your submission A PDF write-up and a video response A full-on research squad (me + AI + friends + network) focused on your submission. Worth way more than $20, kept low so anyone can access it. What do you mean \"a position in the queue\"? When you submit your problem, it enters the queue . You can see all pending submissions there, along with recently completed ones. Every day, FogSift selects items from the queue to work on. Your position tells you roughly where you are in line, but selection isn't strictly first-come-first-served. What do you mean \"up to 1 hour\"? You get up to the full hour. Each submission gets up to 1 hour of focused attention. At or before the hour mark, we stop and draft your PDF write-up and video response. Sometimes we crack it in 20 minutes. Sometimes the full hour isn't enough. Either way, you get what we found. Can I pay to move up in the queue? Yes. There's a daily bump option. Once per day, you can pay a one-time fee to move your submission up. This prevents abuse while giving time-sensitive requests a path forward. The Work Can you refuse to work on my submission? Yes. FogSift reserves the right to refuse any submission for any reason. If we refuse before starting work, you get a full refund. This rarely happens. Do you give specific advice or just frameworks? Both. Concrete recommendations where possible. When not, a framework to figure it out yourself. No vague platitudes. What if I want to work with FogSift more? Start the same as everyone else: submit your problem for $20. Mention that you're interested in deeper engagement. The Video Why do you work on camera? Transparency. You see exactly how I think through problems. No black box consulting. Plus, others can learn from watching. Where are videos published? On the FogSift YouTube channel . Each session becomes an episode. Can I request my video not be published? The public format is core to how this works. If your problem requires confidentiality, consider a private engagement instead. Money Why $20? Low enough to be accessible. High enough to keep submissions real. The price isn't the point; the work is. Do you offer refunds? If your problem sits in the queue for 30+ days without being picked, yes. If you're dissatisfied with the work, let's talk. I'd rather make it right than keep your money. What's the catch? No catch. The low price lets me help more people. The public format means the value compounds as others learn from each session. Other Options What if the queue doesn't fit my needs? Check the offers page for other options: free triage calls, private deep dives, and contract engagements for bigger projects. Can I just email you a question? Sure. info@fogsift.com . I can't promise a deep answer for free, but I'll point you in the right direction. Ready to join the queue?"],"content":"FAQ Frequently Asked Questions The Queue What does $20 get me? Your $20 buys you: A position in the queue Up to 1 hour of focused attention on your submission A PDF write-up and a video response A full-on research squad (me + AI + friends + network) focused on your submission. Worth way more than $20, kept low so anyone can access it. What do you mean \"a position in the queue\"? When you submit your problem, it enters the queue . You can see all pending submissions there, along with recently comp","category":"FAQ"},{"url":"portfolio.html","title":"Portfolio","description":"Projects and builds by Christopher Tavolazzi. Hardware, software, AI tools, and everything in between. Watch the full build process on YouTube.","headings":["PORTFOLIO Real projects, built live on camera. Hardware, software, AI tools, and everything in between. Featured &middot; Hardware + Software TMGotcha A modern reimagining of the virtual pet. Modular hardware cubes, collectible editions, desk-friendly displays, and a holographic Pepper's Ghost effect. Tamagotchi meets maker culture. Custom Hardware Embedded Software Product Design 3D Printing Watch the Build CONCEPT ART &amp; DESIGNS Hardware Concept Cube Design Limited Editions Product Lineup Desktop Display Pepper's Ghost Starter &amp; Expansion Box Concept Open Source &middot; AI Framework WAFT An evolutionary code laboratory for self-modifying AI agents. Agents write their own code, spawn variants with mutations, and evolve through directed selection. Genome tracking, fitness evaluation, and complete lineage telemetry. Don't just build agents. Breed them. Python AI Agents Evolutionary Design Open Source View on GitHub AI-NATIVE DEVELOPMENT Every project on this page was built with AI tools. Not as a gimmick&mdash;as a multiplier. Faster iteration, broader exploration, tighter feedback loops. Claude Code AI pair programming. Architecture, generation, and real-time iteration from the terminal. Codex Multi-file prototyping and rapid feature scaffolding. Describe it, build it, ship it. WAFT Framework Custom-built evolutionary lab. AI agents that write, mutate, and improve their own code. Custom Tooling Build scripts, automation pipelines, and dev tools. If a tool doesn't exist yet, I make one. This entire site was built with Claude Code. Watch the process. SKILLS &amp; TOOLS What gets used depends on what the problem needs. Software JavaScript/TypeScript, Python, Node.js, React, Svelte, REST APIs, databases, CI/CD, cloud infrastructure Hardware Arduino, Raspberry Pi, ESP32, 3D printing, PCB design, embedded systems, IoT prototyping Strategy Root cause analysis, process mapping, decision frameworks, systems thinking, competitive analysis WATCH THE BUILDS Every project is documented start to finish. The mistakes, the breakthroughs, and the thinking behind each decision. FogSift on YouTube Visit Channel Subscribe for New Builds Got something you want built?"],"content":"PORTFOLIO Real projects, built live on camera. Hardware, software, AI tools, and everything in between. Featured &middot; Hardware + Software TMGotcha A modern reimagining of the virtual pet. Modular hardware cubes, collectible editions, desk-friendly displays, and a holographic Pepper's Ghost effect. Tamagotchi meets maker culture. Custom Hardware Embedded Software Product Design 3D Printing Watch the Build CONCEPT ART &amp; DESIGNS Hardware Concept Cube Design Limited Editions Product Lineup D","category":"Portfolio"},{"url":"contact.html","title":"Contact","description":"Get in touch with Fogsift. Submit a problem for $20, ask a free question, or book a triage call.","headings":["CONTACT Have a question, a problem, or an idea? Pick the option that fits. Email Us Questions, ideas, or just curious. No pressure, no pitch. Send an Email Free &middot; info@fogsift.com Book a Call 15-30 min triage call to figure out what you actually need. Schedule a Call Free &middot; No obligation Join the Queue Full focus session. You get a PDF write-up and video response. Submit a Problem $20 &middot; See the queue WHAT PEOPLE ASK ABOUT Tech that isn't working Apps crashing, integrations failing, builds breaking Processes that feel broken Bottlenecks, handoff failures, invisible waste Decisions they're stuck on Build vs. buy, hire vs. outsource, pivot vs. stay Ideas to pressure-test Business models, product concepts, side projects Things nobody else will look at Weird data, legacy systems, \"it's always been that way\" WHAT TO INCLUDE &#10003; What's the problem you're trying to solve? &#10003; What have you already tried? &#10003; What would success look like? &#10003; Any privacy or anonymization needs? Don't worry if you don't have all the answers. That's what we figure out together. QUICK ANSWERS What if you can't solve my problem? You still get the PDF write-up and video response, plus a narrower problem statement or referral. The $20 covers the session, not a guaranteed fix. How long until I hear back? We review submissions daily and work through the queue in order. Most submissions are addressed within a week. Is my submission confidential? We may publish a video response. Your submission may be used for marketing. You can request anonymization at any time. Can I get a refund? If we haven't started work yet, yes. Once we begin the session, the $20 is non-refundable. See our Terms . More questions? See the full FAQ . FIND US ELSEWHERE"],"content":"CONTACT Have a question, a problem, or an idea? Pick the option that fits. Email Us Questions, ideas, or just curious. No pressure, no pitch. Send an Email Free &middot; info@fogsift.com Book a Call 15-30 min triage call to figure out what you actually need. Schedule a Call Free &middot; No obligation Join the Queue Full focus session. You get a PDF write-up and video response. Submit a Problem $20 &middot; See the queue WHAT PEOPLE ASK ABOUT Tech that isn't working Apps crashing, integrations f","category":"Contact"},{"url":"vision.html","title":"Vision","description":"Our vision for the future: building sustainable spaces, documenting the journey, and preparing for a post-labor world where technology serves everyone.","headings":["VISION Building for a future where technology serves everyone. Image via Solarpunk Station The Dream We're working toward something simple: build a shop house on our own land , live in an RV while we film the entire process, and share what we learn on the FogSift YouTube channel . Not for fame. Not for followers. Just to show other people that it's possible. That you can build your own space, document the mistakes, and help others skip the learning curve. The content stays mostly anonymous. The focus is on the work, not the personality. Post-Labor Thinking We're planning for a world that doesn't exist yet, but might soon. Advanced robotics and AI are accelerating faster than most people realize. Within our lifetimes, machines could handle most of what we currently call \"work\" - automatically, efficiently, and eventually for near-zero marginal cost. If we get this transition right , it's abundance. Universal access to food, shelter, healthcare, education. People freed to create, explore, connect, and rest. If we get it wrong , it's a different story. Concentrated ownership, mass displacement, surveillance capitalism on steroids. We're betting on the first outcome - and building as if it's already here. WHAT WE'RE BUILDING TOWARD Self-Sufficient Space A shop house on our own property. Workshop downstairs, living space above. Solar power, rainwater collection, food gardens. Documented Process Every step filmed and shared. The permits, the mistakes, the costs, the solutions. Real information for real people. Open Knowledge Everything we learn goes public. Building codes, material choices, tool reviews, lessons learned. No gatekeeping. Why This Matters Housing is broken. The system that was supposed to provide shelter has become a wealth extraction machine. Most people can't afford to buy, can barely afford to rent, and have zero path to ownership. We think there's another way. Not through policy changes or waiting for permission. Through building the thing yourself and showing others how . It's not for everyone. But for the people it's for, it could change everything. FOLLOW ALONG"],"content":"VISION Building for a future where technology serves everyone. Image via Solarpunk Station The Dream We're working toward something simple: build a shop house on our own land , live in an RV while we film the entire process, and share what we learn on the FogSift YouTube channel . Not for fame. Not for followers. Just to show other people that it's possible. That you can build your own space, document the mistakes, and help others skip the learning curve. The content stays mostly anonymous. The ","category":"Vision"},{"url":"terms.html","title":"Terms & Conditions","description":"Terms and conditions for FogSift's Move the Needle offer. Read before participating.","headings":["TERMS & CONDITIONS For FogSift's \"Move the Needle\" Queue Offer 1. What This Is Your $20 payment holds a spot in the queue. That's it. This is not a work contract, consulting agreement, or promise of specific deliverables. It's a payment to reserve time and attention from FogSift until we can get to your request. We're a small operation trying to monetize a YouTube channel by helping people with DIY projects and problem-solving. We're figuring this out as we go, and we appreciate your patience. 2. What You Might Get If and when we address your request, you may receive some combination of: A PDF report with our findings A short video response (usually 15-90 seconds) Possibly a longer YouTube video, at our discretion None of this is guaranteed. We reserve the right to decline any request for any reason, and we'll issue a refund if we do. 3. Don't Submit Anything illegal or unethical Financial advice questions, investment decisions, or securities stuff Requests targeting specific people, personal disputes, harassment, or doxxing Confidential info you don't have permission to share Anything you don't own or have rights to When in doubt, don't submit it. 4. No Guarantees We cannot guarantee: When we'll get to your request (could be days, could be weeks) What the outcome will be That your data is 100% secure (we do our best, but the internet is the internet) Submit at your own risk. Don't send anything you'd panic about if it leaked. 5. Our Capacity We try to address up to 2 requests per day. Some days that happens, some days it doesn't. Life, health, and sanity come first. We won't take on more than we can handle. We'd rather do fewer things well than many things poorly. 6. Refunds Request a refund through Ko-fi if: We haven't addressed your request yet You changed your mind Any reason, really No hard feelings. We'd rather you ask for your money back than feel stuck. 7. Age Requirement You must be 18 or older to participate. If you're under 18, a parent or guardian must submit the request on your behalf, with their payment method, and their active involvement. We're not set up to work directly with minors. 8. Content & Your Submission What we know: We might turn your request into YouTube content If you want privacy, tell us clearly in your submission We'll do our best to respect your wishes, but we can't guarantee anything submitted online stays private We're not trying to steal anyone's ideas or content We're learning as we go. If something feels off, talk to us. 9. We're Not Liable FogSift is not responsible for: Decisions you make based on our response Things outside our control (security breaches, platform issues, etc.) Your expectations not matching reality This is experimental. We're doing our best. 10. This Can Change"],"content":"TERMS & CONDITIONS For FogSift's \"Move the Needle\" Queue Offer 1. What This Is Your $20 payment holds a spot in the queue. That's it. This is not a work contract, consulting agreement, or promise of specific deliverables. It's a payment to reserve time and attention from FogSift until we can get to your request. We're a small operation trying to monetize a YouTube channel by helping people with DIY projects and problem-solving. We're figuring this out as we go, and we appreciate your patience. 2","category":"Legal"},{"url":"privacy.html","title":"Privacy Policy","description":"Fogsift privacy policy and data handling practices.","headings":["Privacy Policy Last Updated: December 2025 Overview Fogsift respects your privacy. This policy describes how we handle information when you visit our website or use our services. Information We May Collect When you interact with our website or services, we may collect certain information, which could include: Information you voluntarily provide (such as when contacting us) Standard technical information automatically collected by web servers Cookies or similar technologies for basic site functionality How We Use Information Any information collected may be used to: Respond to your inquiries Provide requested services Improve our website and services Comply with legal obligations Information Sharing We do not sell personal information. We may share information as required by law, or with service providers who assist in our operations, subject to appropriate confidentiality agreements. Third-Party Services Our website may use third-party services (such as hosting providers, analytics, or fonts) that have their own privacy policies. We encourage you to review their policies. Your Rights Depending on your location, you may have certain rights regarding your personal information under applicable laws. Please contact us if you have questions about your rights. Changes to This Policy We may update this policy from time to time. Changes will be posted on this page with an updated revision date. Contact"],"content":"Privacy Policy Last Updated: December 2025 Overview Fogsift respects your privacy. This policy describes how we handle information when you visit our website or use our services. Information We May Collect When you interact with our website or services, we may collect certain information, which could include: Information you voluntarily provide (such as when contacting us) Standard technical information automatically collected by web servers Cookies or similar technologies for basic site functio","category":"Legal"},{"url":"disclaimer.html","title":"Disclaimer","description":"Fogsift legal disclaimer and terms of service.","headings":["Disclaimer Last Updated: December 2025 General Disclaimer The information and services provided by Fogsift are offered in good faith and for general informational purposes. We make no warranties or representations of any kind, express or implied, regarding the completeness, accuracy, reliability, or suitability of any information or services. Professional Services Fogsift provides consulting and advisory services. Any recommendations, strategies, or guidance provided should not be construed as professional advice in any regulated field (legal, financial, medical, etc.) unless explicitly stated otherwise by a qualified professional. Compliance with Laws Fogsift operates in compliance with all applicable federal, state, and local laws and regulations. We are committed to conducting business ethically and lawfully. Right to Refuse Service Fogsift reserves the right to refuse service to any individual or entity, at any time, for any reason permitted by applicable law. This right is exercised at our sole discretion and in accordance with all applicable legal requirements. Reporting Obligations Fogsift will comply with all applicable legal reporting requirements. Where required by law, we will cooperate with appropriate authorities and disclose information as necessary to fulfill our legal obligations. Limitation of Liability To the fullest extent permitted by applicable law, Fogsift shall not be liable for any indirect, incidental, special, consequential, or punitive damages arising from or related to your use of our services or reliance on any information provided. Indemnification By using our services, you agree to indemnify and hold harmless Fogsift and its principals from any claims, damages, or expenses arising from your use of our services or violation of these terms. Changes We reserve the right to modify this disclaimer at any time. Continued use of our services following any changes constitutes acceptance of those changes. Governing Law This disclaimer and any disputes arising from it shall be governed by and construed in accordance with applicable laws. Contact"],"content":"Disclaimer Last Updated: December 2025 General Disclaimer The information and services provided by Fogsift are offered in good faith and for general informational purposes. We make no warranties or representations of any kind, express or implied, regarding the completeness, accuracy, reliability, or suitability of any information or services. Professional Services Fogsift provides consulting and advisory services. Any recommendations, strategies, or guidance provided should not be construed as p","category":"Legal"},{"url":"wiki/case-studies/communication-breakdown.html","title":"Case Study: The Communication Breakdown","description":"---","headings":["Case Study: The Communication Breakdown Industry: Professional Services Problem Type: Organizational Duration: 4 weeks Outcome: Project delivery time reduced 35% The Situation A professional services firm was bleeding. Projects consistently ran over budget and past deadline. Client satisfaction was declining. Key employees were burning out and leaving. What we heard initially: &quot;Our project managers need better tools&quot; &quot;The teams aren&#39;t communicating&quot; &quot;We&#39;ve grown too fast&quot; The Investigation Week 1: Stakeholder Mapping We interviewed: 8 project managers 12 practitioners (consultants, analysts) 4 partners 3 clients (with permission) Each interview focused on: What works? What doesn&#39;t? Where does information get stuck? Week 2: Process Observation We shadowed two active projects. Sat in meetings. Watched handoffs. Tracked information flow. Key observation: Information moved vertically (up to partners, down to teams) but not horizontally (between teams, between projects). A question from one team that could be answered by another team instead went up to a partner, then came back down. Two-day round trip for a five-minute conversation. Week 3: Root Cause Analysis Symptom: Projects running late Direct cause: Rework and waiting Why rework?: Misunderstood requirements Why misunderstood?: Incomplete handoffs Why incomplete?: No handoff protocol Why no protocol?: &quot;Partners just knew&quot; Symptom: Budget overruns Direct cause: Scope changes mid-project Why scope changes?: Client expectations unclear Why unclear?: Proposal-to-kickoff gap Why gap?: Partners sold, different team delivered The Pattern: The firm had grown from 15 to 80 people in three years. What worked with 15 people (informal coordination, partner omniscience) broke at 80. The communication infrastructure never scaled. Week 4: Structural Analysis We mapped the actual communication network versus the org chart. See Field Note: The Map Is Not The Territory . The org chart showed clear reporting lines. Reality showed: Partners as information bottlenecks Senior practitioners bypassing managers No horizontal connections between teams Critical knowledge in email, not shared systems The Findings Root cause: Communication infrastructure didn&#39;t scale with organization size. Specifically: No structured handoffs: Knowledge transfer between phases was informal Partner bottleneck: All decisions funneled through partners Siloed teams: No mechanisms for cross-team learning Documentation gaps: Project knowledge lived in individuals The Recommendations Immediate (Week 1-2) Structured kickoff protocol Mandatory 90-minute kickoff meeting Defined attendees: selling partner, delivery lead, full team Standard agenda covering scope, constraints, success criteria Written summary distributed same day Decision delegation matrix Document which decisions require partner approval Everything else delegated to project managers Published and enforced Short-term (Month 1-2) Project retrospectives Mandatory 60-minute debrief at project close What worked, what didn&#39;t, what to do differently Lessons documented in searchable repository Cross-team standups Weekly 15-minute all-hands standup Each team: what they&#39;re working on, what&#39;s blocking them Creates horizontal visibility Medium-term (Month 2-4) Knowledge management system Central repository for project artifacts Searchable lessons learned Templates and playbooks Communication training For project managers: facilitation, escalation, handoffs For practitioners: documentation, status reporting The Implementation The firm implemented recommendations 1-4 immediately. Recommendation 5 was in progress at engagement end. Recommendation 6 was scheduled for the following quarter. The Outcome After 6 months: On-time delivery: 58% ‚Üí 82% Budget accuracy: +/- 30% ‚Üí +/- 12% Client satisfaction (NPS): +15 points Employee turnover: Declined 40% Qualitative changes: Partners reported feeling &quot;less essential to every decision&quot; Project managers reported &quot;actually being able to manage&quot; Practitioners reported &quot;knowing what I&#39;m walking into&quot; Key Lessons Informal works until it doesn&#39;t What works at 15 people breaks at 80. The point of breakdown isn&#39;t predictable, but it&#39;s inevitable. Bottlenecks aren&#39;t always machines The partners were human bottlenecks. They meant well. They were trying to help. But they were also the constraint. Communication is infrastructure It requires design, investment, and maintenance just like any other system. The problem you&#39;re told isn&#39;t the problem &quot;We need better tools&quot; was a symptom. The root cause was organizational design that hadn&#39;t evolved. Growing is easy. Scaling is hard. The difference is infrastructure. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Case Study: The Communication Breakdown Industry: Professional Services Problem Type: Organizational Duration: 4 weeks Outcome: Project delivery time reduced 35% The Situation A professional services firm was bleeding. Projects consistently ran over budget and past deadline. Client satisfaction was declining. Key employees were burning out and leaving. What we heard initially: &quot;Our project managers need better tools&quot; &quot;The teams aren&#39;t communicating&quot; &quot;We&#39;ve grown ","category":"Wiki"},{"url":"wiki/case-studies/manufacturing-throughput.html","title":"Case Study: Manufacturing Throughput Crisis","description":"---","headings":["Case Study: Manufacturing Throughput Crisis Industry: Precision Manufacturing Problem Type: Operations Duration: 6 weeks Outcome: 45% throughput increase The Situation A precision manufacturing company producing aerospace components faced a throughput crisis. Despite significant investment in new CNC equipment, output had plateaued. Customer orders were backlogging, and the company was at risk of losing key contracts. What we heard initially: &quot;The new machines aren&#39;t performing to spec&quot; &quot;We need to add a night shift&quot; &quot;The operators need more training&quot; The Investigation Week 1-2: Symptom Mapping We started by documenting exactly what &quot;throughput crisis&quot; meant: Output: 850 units/week (target: 1,200) Utilization: 62% (claimed), actual TBD Backlog: 6 weeks and growing Quality: 4.2% rejection rate Week 2-3: Process Tracing We followed the flow from raw material to shipping: Material receiving: No delays observed Machining (3 CNC cells): High variability in cycle times Deburring: Manual, consistent pace Inspection: Significant queuing observed Assembly: Waiting for inspected parts Shipping: On-time once parts available The inspection queue was the first clue. Parts were piling up waiting for quality verification. Week 3-4: Root Cause Analysis Inspection Bottleneck The quality department had three inspectors. Inspection time averaged 12 minutes per part. Capacity: ~120 parts per day across all inspectors. Production was capable of ~200 parts per day. No matter how fast production ran, inspection could only process 120 parts daily. The gap accumulated as backlog. But why was inspection so slow? We dug deeper. Inspectors were following an outdated procedure that required: 23-point manual measurement Full documentation on paper forms Secondary verification for every part This procedure was written when the company produced 15 different part numbers. They now produced 180. The procedure had never been updated. Secondary finding: Setup time waste While investigating, we noticed machine setup times varied wildly: 45 minutes to 4 hours for the same part. Tribal knowledge problem. Some operators knew the tricks; others didn&#39;t. See Field Note: Tribal Knowledge . The Findings Root cause 1: Inspection procedure misaligned with current production volume and part variety. Designed for a different era. Root cause 2: Undocumented setup procedures leading to variable machine utilization. Contributing factors: No capacity planning across departments Inspection treated as separate from production Resistance to procedure changes due to aerospace certification concerns The Recommendations Immediate (Week 1-2) Risk-stratify inspection Not all parts need 23 measurement points Implement tiered inspection based on part criticality and history Predicted reduction: 23 points ‚Üí average of 8 points Cross-train for flexibility Train two production supervisors on basic inspection Allow overflow capacity during peaks Short-term (Month 1-2) Document setup procedures Capture best practices from experienced operators Create standardized setup sheets per part family Target: 90-minute maximum setup time Digital inspection forms Eliminate paper documentation Reduce transcription errors Enable real-time quality tracking Medium-term (Month 2-4) Capacity alignment Match production scheduling to inspection capacity Eliminate production of parts that will sit in queue Quality engineering review With aerospace auditor present Formally revise inspection procedures Certify the streamlined process The Implementation The client implemented recommendations 1-4. Recommendation 5 was partially implemented. Recommendation 6 was deferred due to an upcoming customer audit. The Outcome After 3 months: Output: 1,240 units/week (target exceeded) Utilization: 78% Backlog: 2 weeks (within normal) Quality: 3.8% rejection rate (improved) Quantified impact: 45% throughput increase $2.1M additional annual revenue capacity 0 new equipment purchases needed 0 additional headcount required Key Lessons The bottleneck was invisible Everyone was looking at production. The constraint was in quality. See Field Note: Finding the Bottleneck . Procedures fossilize What was appropriate 10 years ago wasn&#39;t appropriate today. But no one had questioned it. &quot;That&#39;s how we&#39;ve always done it.&quot; Documentation matters The setup time variability was pure tribal knowledge. Once captured, the benefit was immediate. Systems, not people The inspectors weren&#39;t slow. The procedure was wrong. The operators weren&#39;t inconsistent. The knowledge transfer was missing. The solution to a production problem was found in the quality lab. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Case Study: Manufacturing Throughput Crisis Industry: Precision Manufacturing Problem Type: Operations Duration: 6 weeks Outcome: 45% throughput increase The Situation A precision manufacturing company producing aerospace components faced a throughput crisis. Despite significant investment in new CNC equipment, output had plateaued. Customer orders were backlogging, and the company was at risk of losing key contracts. What we heard initially: &quot;The new machines aren&#39;t performing to spec&","category":"Wiki"},{"url":"wiki/case-studies/the-invisible-process.html","title":"Case Study: The Invisible Process","description":"---","headings":["Case Study: The Invisible Process Industry: Healthcare Operations Problem Type: Process Duration: 8 weeks Outcome: 28% reduction in patient wait times The Situation A healthcare network&#39;s outpatient clinics faced chronic patient complaints about wait times. Patients arrived on time for appointments but waited 45-60 minutes to be seen. Patient satisfaction scores were declining. Staff were stressed and defensive. What we heard initially: &quot;Doctors run behind because patients are complex&quot; &quot;We need more exam rooms&quot; &quot;The scheduling system is broken&quot; The Investigation Week 1-2: Data Collection We gathered: Appointment schedules vs. actual start times Patient check-in to rooming timestamps Provider arrival times Room utilization rates Staff interviews Key finding: The data infrastructure was poor. Timestamps were unreliable. No one was actually measuring wait time systematically. Week 3-4: Process Mapping We physically observed patient flow at three clinics. Stopwatch in hand. Every step documented. The official process: Patient arrives Front desk checks in patient Patient waits MA rooms patient, takes vitals Patient waits Provider sees patient What we actually observed: Patient arrives (often early, as instructed) Front desk checks in patient (2-5 minutes) Patient waits (variable: 5-45 minutes) MA rooms patient (5-8 minutes) Patient waits in room (variable: 10-40 minutes) Provider sees patient But we also found shadow processes: MAs taking unscheduled vital sign re-checks Providers hunting for missing lab results Front desk calling patients who hadn&#39;t shown Providers documenting previous patient&#39;s chart before rooming next &quot;Quick questions&quot; from staff interrupting providers Week 5-6: Root Cause Analysis We traced the wait time to its sources: Wait 1 (lobby): Patient arrives early (instructed to arrive 15 min early) Check-in paperwork (redundant with portal) MA waiting for room to open Insurance verification delays Wait 2 (exam room): Provider finishing previous patient&#39;s documentation Provider answering &quot;quick questions&quot; Provider hunting for information (labs, notes, imaging) No signal when room is ready The invisible process was documentation. Providers spent as much time documenting as they did seeing patients. And most documentation happened between patients, causing the next patient to wait. Week 7-8: Validation We tested our hypothesis by tracking documentation patterns: Average documentation time per visit: 18 minutes Percentage done between patients: 73% Average delay caused: 12 minutes per patient Compounded across a day, this explained most of the wait time. The Findings Root cause: Documentation workflow was invisible, unmeasured, and unmanaged. It was treated as &quot;part of the appointment&quot; rather than a separate process with its own optimization needs. Contributing factors: Early arrival instructions (patients arrived before system was ready) No visual signals for room readiness No protected documentation time Frequent interruptions during documentation Information scattered across systems The Recommendations Immediate (Week 1-2) Adjust arrival instructions &quot;Arrive 15 minutes early&quot; ‚Üí &quot;Arrive 5 minutes early&quot; Online check-in preferred Visual room signals Simple flag system: room ready, patient in room, provider needed Eliminates hunting and waiting Short-term (Month 1-2) Protected documentation blocks Last 15 minutes of morning and afternoon reserved No patients scheduled during this time Documentation caught up before it compounds Pre-visit preparation MAs prepare chart before patient arrives Flag missing information before visit, not during Reduce provider search time Medium-term (Month 2-4) Documentation workflow redesign Scribes for high-volume providers Template optimization for common visit types Voice dictation for narrative notes Interruption protocol Define what qualifies as urgent Batch non-urgent questions Designate &quot;interruptible&quot; times The Implementation The network piloted recommendations 1-4 at one clinic. After validation, rolled out to all locations. Recommendations 5-6 were in planning at engagement end. The Outcome Pilot clinic, after 3 months: Average wait time: 52 min ‚Üí 37 min (28% reduction) On-time appointment start: 31% ‚Üí 58% Patient satisfaction: +12 points Provider satisfaction: +8 points (unexpected bonus) System-wide, after 6 months: Average wait time reduced 24% Patient complaints about wait time: -45% Zero additional rooms or staff required Key Lessons The invisible process was the problem Documentation was treated as invisible overhead, not as a process with its own requirements. Once made visible, it could be managed. Data infrastructure matters Without reliable timestamps, you can&#39;t measure. Without measurement, you can&#39;t improve. Blame obscured the cause &quot;Patients are complex&quot; was technically true but not actionable. The real cause was workflow design, which was actionable. Small changes compound No single intervention fixed everything. But arrival timing + room signals + documentation blocks combined to significant improvement. What you can&#39;t see, you can&#39;t manage. What you can&#39;t manage, you can&#39;t improve. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Case Study: The Invisible Process Industry: Healthcare Operations Problem Type: Process Duration: 8 weeks Outcome: 28% reduction in patient wait times The Situation A healthcare network&#39;s outpatient clinics faced chronic patient complaints about wait times. Patients arrived on time for appointments but waited 45-60 minutes to be seen. Patient satisfaction scores were declining. Staff were stressed and defensive. What we heard initially: &quot;Doctors run behind because patients are complex&q","category":"Wiki"},{"url":"wiki/concepts/cognitive-biases.html","title":"Cognitive Biases","description":"Cognitive biases are systematic patterns of deviation from rational judgment. They're mental shortcuts that usually help but sometimes mislead. Understanding th","headings":["Cognitive Biases Cognitive biases are systematic patterns of deviation from rational judgment. They&#39;re mental shortcuts that usually help but sometimes mislead. Understanding them helps you think more clearly and diagnose problems more accurately. Why Biases Matter for Diagnosis When investigating problems: You will be biased in how you gather and interpret evidence Stakeholders will be biased in what they tell you The organization will have embedded biases in its culture and processes Awareness doesn&#39;t eliminate bias, but it reduces its impact. Key Biases in Problem-Solving Confirmation Bias What it is: Seeking evidence that confirms what you already believe and ignoring evidence that contradicts it. How it shows up: Interviewing people you expect to agree with you first Dismissing data that doesn&#39;t fit your theory Asking leading questions that prompt expected answers Countermeasure: Actively seek disconfirming evidence. Ask &quot;what would prove me wrong?&quot; and then look for it. Availability Bias What it is: Overweighting information that comes to mind easily, usually because it&#39;s recent, vivid, or emotionally charged. How it shows up: Focusing on the dramatic failure, not the mundane causes Giving too much weight to the last thing someone told you Thinking rare events are common because they&#39;re memorable Countermeasure: Seek systematic data, not anecdotes. Ask &quot;what am I not seeing because it&#39;s not memorable?&quot; Anchoring What it is: Over-relying on the first piece of information encountered, even if it&#39;s arbitrary. How it shows up: Estimating based on numbers that were mentioned, even irrelevant ones Starting investigations where someone else pointed, without questioning why Getting stuck on the first explanation offered Countermeasure: Generate your own estimates before looking at others. Consider multiple starting points. Fundamental Attribution Error What it is: Attributing others&#39; behavior to their character while attributing your own behavior to circumstances. How it shows up: &quot;They made a mistake because they&#39;re careless&quot; vs. &quot;I made a mistake because I was rushed&quot; Blaming individuals when systems failed them Ignoring context when judging performance Countermeasure: Always ask about circumstances before concluding about character. &quot;What about the situation made this behavior likely?&quot; Hindsight Bias What it is: Believing, after an event, that you would have predicted it. &quot;I knew it all along.&quot; How it shows up: Judging past decisions by outcomes rather than the information available at the time Underestimating how uncertain the situation was Assuming failures were predictable and therefore someone&#39;s fault Countermeasure: Reconstruct what was known at the time. Judge decisions by process, not just outcomes. Sunk Cost Fallacy What it is: Continuing to invest in something because of what you&#39;ve already invested, rather than evaluating future value. How it shows up: &quot;We&#39;ve already spent $2M, we can&#39;t stop now&quot; Continuing failed initiatives because abandoning them feels like waste Escalating commitment to failing strategies Countermeasure: Evaluate decisions based on future costs and benefits only. Past investment is irrelevant to future value. Survivorship Bias What it is: Drawing conclusions from successes without considering the failures that didn&#39;t survive to be observed. How it shows up: &quot;These successful companies all did X, so X causes success&quot; Ignoring failed projects when analyzing what works Learning only from visible examples Countermeasure: Ask &quot;what about the ones that didn&#39;t make it?&quot; Seek out failure data. Status Quo Bias What it is: Preferring the current state of affairs over change, even when change would be beneficial. How it shows up: Resistance to new processes, tools, or structures Framing change as risky and staying the same as safe Requiring more evidence for change than for continuity Countermeasure: Evaluate the current state as rigorously as you would a proposed change. What&#39;s the cost of not changing? Dunning-Kruger Effect What it is: People with low competence overestimate their ability, while experts underestimate theirs. How it shows up: Confident but wrong stakeholders Experts who hedge too much Resistance to outside perspective Countermeasure: Calibrate confidence against track record. Seek feedback from people with different expertise levels. Organizational Biases Beyond individual biases, organizations develop collective biases: Groupthink Agreement driven by social pressure rather than evidence. Everyone nods, but nobody actually believes it. NIH (Not Invented Here) Dismissing external ideas because they weren&#39;t developed internally. Success Theater Reporting what&#39;s going well while hiding what&#39;s failing. Tyranny of Metrics Optimizing for measurable targets at the expense of unmeasured (but important) outcomes. Using Bias Awareness In Yourself Before concluding, ask: &quot;What bias might be affecting my judgment here?&quot; Seek evidence that would prove you wrong Get outside perspectives In Stakeholders Recognize that what they tell you is filtered through their biases Ask questions that bypass common biases Triangulate across multiple sources In Organizations Identify systemic biases in culture and process Design countermeasures into processes Create safe spaces for dissent Bias is unavoidable. Unawareness of bias is not. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Cognitive Biases Cognitive biases are systematic patterns of deviation from rational judgment. They&#39;re mental shortcuts that usually help but sometimes mislead. Understanding them helps you think more clearly and diagnose problems more accurately. Why Biases Matter for Diagnosis When investigating problems: You will be biased in how you gather and interpret evidence Stakeholders will be biased in what they tell you The organization will have embedded biases in its culture and processes Aware","category":"Wiki"},{"url":"wiki/concepts/mental-models.html","title":"Mental Models","description":"Mental models are frameworks for understanding how things work. They simplify complex reality into patterns we can reason about. The quality of your thinking de","headings":["Mental Models Mental models are frameworks for understanding how things work. They simplify complex reality into patterns we can reason about. The quality of your thinking depends on the quality of your models. What is a Mental Model? A mental model is a simplified representation of reality that helps you: Predict outcomes Make decisions Understand systems Communicate with others Every model is incomplete. Every model is wrong in some ways. The goal isn&#39;t perfect models. It&#39;s useful models. Why Models Matter You Already Use Models Whether you know it or not, you&#39;re already thinking in models: &quot;If I drop this, it falls&quot; (gravity model) &quot;If I raise prices, demand decreases&quot; (supply/demand model) &quot;If I work harder, I&#39;ll succeed&quot; (effort/reward model) The question isn&#39;t whether to use models. It&#39;s whether your models are any good. Bad Models Cause Bad Decisions If your model of reality doesn&#39;t match reality, your predictions will be wrong and your decisions will fail. Example: A manager believes &quot;employees are motivated primarily by money.&quot; This model leads to compensation-focused retention strategies. When employees leave for jobs with lower pay but better culture, the manager is confused. The model was wrong. Multiple Models Beat Single Models No single model captures all of reality. The more models you have, the more perspectives you can take. Charlie Munger calls this &quot;mental model diversity.&quot; Core Models for Problem-Solving First Principles Break problems down to their fundamental truths and build up from there. Don&#39;t reason by analogy unless you understand why the analogy holds. Inversion Instead of asking &quot;how do I succeed?&quot;, ask &quot;what would guarantee failure?&quot; Then avoid those things. Second-Order Effects Ask not just &quot;what happens next?&quot; but &quot;and then what?&quot; Most mistakes come from ignoring downstream consequences. See Second-Order Effects . Map vs Territory The model is not the reality. The org chart is not the organization. The metric is not the outcome. The description is not the thing. See Field Note: The Map Is Not The Territory . Occam&#39;s Razor Among competing explanations, prefer the simplest one that fits the evidence. Don&#39;t multiply entities unnecessarily. Hanlon&#39;s Razor Never attribute to malice what can be adequately explained by ignorance, confusion, or miscommunication. Margin of Safety Design for more stress than you expect. Build buffers. Assume your estimates are optimistic. Feedback Loops Understand how outputs become inputs. See Feedback Loop Analysis . Developing Better Models Collect Models Actively Read widely across disciplines. Physics, biology, economics, psychology, history, engineering: each field has developed models that apply far beyond their original domain. Test Models Against Reality When a model predicts something, check whether it happens. When predictions fail, update the model. Notice When Models Conflict If two of your models give different answers, at least one is wrong (or you&#39;re applying them incorrectly). Investigate. Hold Models Loosely Strong opinions, loosely held. Be willing to abandon a model when evidence contradicts it. Understand Model Limits Every model has boundary conditions where it stops working. Know what those are. Common Model Failures Using the Wrong Model Applying a model outside its domain. Not every problem is a nail. Not every solution is a hammer. Confusing Model with Reality Forgetting that the model is a simplification. The stock price is not the company. The grade is not the learning. Ignoring Unfamiliar Models Dismissing models from other fields because they&#39;re unfamiliar. Physics has much to teach business. Biology has much to teach software. Model Lock-In Using the same model for every problem because it worked before. Past success with a model doesn&#39;t guarantee future applicability. Building Your Model Toolkit Start with fundamentals: Understand the basic models in this wiki Practice applying them to real situations Notice when they work and when they don&#39;t Add new models from diverse sources Develop intuition for which model fits which situation The map is not the territory, but a good map still beats wandering blind. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Mental Models Mental models are frameworks for understanding how things work. They simplify complex reality into patterns we can reason about. The quality of your thinking depends on the quality of your models. What is a Mental Model? A mental model is a simplified representation of reality that helps you: Predict outcomes Make decisions Understand systems Communicate with others Every model is incomplete. Every model is wrong in some ways. The goal isn&#39;t perfect models. It&#39;s useful mode","category":"Wiki"},{"url":"wiki/concepts/root-cause.html","title":"Root Cause Analysis","description":"Root cause analysis is the systematic process of tracing a problem back to its origin. It's not about fixing symptoms. It's about finding the actual source.","headings":["Root Cause Analysis Root cause analysis is the systematic process of tracing a problem back to its origin. It&#39;s not about fixing symptoms. It&#39;s about finding the actual source. The Principle &quot;For every complex problem, there is an answer that is clear, simple, and wrong.&quot; - H.L. Mencken Most organizations treat symptoms. They see a fire and reach for a hose. But fires have ignition points. Find the ignition point, and you don&#39;t need the hose. The Method 1. Document the Symptom What exactly is happening? When did it start? Who noticed it first? 2. Trace the Wire Follow the causal chain backwards. Every effect has a cause. Every cause has a prior cause. 3. Apply the 5 Whys Ask &quot;why&quot; at each step. Don&#39;t stop at the comfortable answer. Example: Why did the server crash? ‚Üí Memory leak Why was there a memory leak? ‚Üí Unclosed database connections Why weren&#39;t connections closed? ‚Üí No timeout configured Why was there no timeout? ‚Üí Default settings copied from prototype Why were prototype settings used? ‚Üí No deployment checklist The root cause isn&#39;t &quot;memory leak.&quot; It&#39;s &quot;no deployment checklist.&quot; Common Traps Premature Closure Stopping at the first plausible explanation. The real cause is usually 2-3 layers deeper. Blame Assignment &quot;Human error&quot; is not a root cause. It&#39;s a symptom of a system that allows humans to err. Confirmation Bias Looking for evidence that supports your initial theory instead of testing it. When to Use This Root cause analysis is expensive. It requires time, access, and honest answers. Use it when: The same problem keeps recurring The cost of the problem justifies the investigation You suspect the &quot;obvious&quot; fix won&#39;t work See also: Field Note: The Map Is Not The Territory Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Root Cause Analysis Root cause analysis is the systematic process of tracing a problem back to its origin. It&#39;s not about fixing symptoms. It&#39;s about finding the actual source. The Principle &quot;For every complex problem, there is an answer that is clear, simple, and wrong.&quot; - H.L. Mencken Most organizations treat symptoms. They see a fire and reach for a hose. But fires have ignition points. Find the ignition point, and you don&#39;t need the hose. The Method 1. Document the Symp","category":"Wiki"},{"url":"wiki/concepts/second-order-effects.html","title":"Second-Order Effects","description":"First-order effects are the direct, immediate consequences of an action. Second-order effects are the consequences of those consequences. Most strategic mistake","headings":["Second-Order Effects First-order effects are the direct, immediate consequences of an action. Second-order effects are the consequences of those consequences. Most strategic mistakes come from ignoring second-order effects. The Concept When you do something, ask: First order: What happens next? Second order: And then what? Third order: And after that? Keep going until the effects become negligible or unpredictable. Why Second-Order Thinking Matters First-Order Thinking is Easy &quot;If we lower prices, we&#39;ll sell more.&quot; That&#39;s first-order. &quot;If we lower prices, competitors will respond, margins will shrink across the industry, and we&#39;ll need to cut costs, which might affect quality.&quot; That&#39;s second-order. The first analysis tells you what you want to hear. The second tells you what will actually happen. Most Decisions Stop at First Order People stop thinking when they reach a satisfying answer. Satisfying doesn&#39;t mean correct. Example: &quot;Let&#39;s add this feature because users requested it.&quot; First order: Users get the feature Second order: Product complexity increases Third order: Support costs rise, other features get delayed Fourth order: Core product identity becomes unclear Fifth order: You&#39;ve built a bloated product that satisfies no one well Failures Come from Later Orders The policies that fail spectacularly are usually fine at the first order. It&#39;s the second, third, and fourth orders where things break. Patterns to Watch Compensating Behavior When you change something, people adjust. Their adjustments often offset your change. Example: Speed bumps to slow traffic First order: Cars slow down at the bump Second order: Drivers compensate by speeding between bumps Third order: Average speed unchanged, but speed variance increases Result: Possibly more dangerous than before Resource Reallocation When you add resources in one place, they often come from another place. Example: Hiring more people for a struggling project First order: More capacity on this project Second order: Other projects lose people or priority Third order: Those projects fall behind Fourth order: Organization is no better off, just redistributed problems Incentive Distortion When you incentivize something, you get more of it, including gaming the incentive. Example: Bonuses for hitting sales targets First order: Sales team pushes harder Second order: Sales team games timing (pull forward, push back deals) Third order: Customers learn to wait for quarter-end deals Fourth order: Consistent sales become impossible; everything bunches at quarter-end Fifth order: Revenue becomes unpredictable Capability Atrophy When you solve a problem externally, internal capability to solve it declines. Example: Outsourcing IT First order: IT costs decrease Second order: Internal IT knowledge erodes Third order: Dependence on vendor increases Fourth order: Negotiating leverage decreases Fifth order: IT costs increase above original level How to Think Second-Order Ask &quot;And Then What?&quot; After every consequence you identify, ask what happens next. Don&#39;t stop until you&#39;ve gone at least three levels deep. Consider All Stakeholders Each stakeholder will respond to your action. What do competitors do? What do customers do? What do employees do? What do regulators do? Look for Feedback Will the consequences feed back into the original cause? Will they amplify or dampen the effect? Consider Time Horizons Second-order effects often unfold over longer timescales. A quarterly decision might have annual consequences. Invert Ask: &quot;What would make this fail?&quot; The answer is often a second-order effect you haven&#39;t considered. Example: Full Analysis Decision: Reduce inventory to cut costs First-order effects: Carrying costs decrease Cash flow improves Second-order effects: Stock-out risk increases Suppliers have less buffer for demand spikes Purchasing frequency increases Third-order effects: Customer complaints about availability More frequent supplier negotiations and orders Transportation costs increase (smaller, more frequent shipments) Fourth-order effects: Customer loyalty decreases Supplier relationships strain Administrative burden increases Fifth-order effects: Revenue decline from lost customers Higher procurement costs from damaged supplier relationships Need to hire more purchasing staff Net assessment: The first-order cost savings may be completely offset or exceeded by later-order effects. Before deciding, quantify the likely second-order impacts and decide whether the tradeoff is worth it. Building the Skill Practice on Past Decisions Take a decision that didn&#39;t work out. Trace the causal chain. Where did later-order effects cause the failure? Make It Explicit When proposing decisions, include a &quot;second-order effects&quot; section. Force yourself and others to think beyond the immediate. Create Delays Between proposal and decision, insert time for reflection. Immediate decisions favor first-order thinking. Use Devil&#39;s Advocates Assign someone to find the second-order problems with every proposal. First-order thinkers solve problems that come back. Second-order thinkers solve problems that stay solved. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Second-Order Effects First-order effects are the direct, immediate consequences of an action. Second-order effects are the consequences of those consequences. Most strategic mistakes come from ignoring second-order effects. The Concept When you do something, ask: First order: What happens next? Second order: And then what? Third order: And after that? Keep going until the effects become negligible or unpredictable. Why Second-Order Thinking Matters First-Order Thinking is Easy &quot;If we lower ","category":"Wiki"},{"url":"wiki/concepts/signal-vs-noise.html","title":"Signal vs Noise","description":"Not all information is equal. Signal is information that tells you something true about reality. Noise is information that doesn't. The ability to distinguish b","headings":["Signal vs Noise Not all information is equal. Signal is information that tells you something true about reality. Noise is information that doesn&#39;t. The ability to distinguish between them is fundamental to diagnosis. The Distinction Signal Signal is information that: Reflects actual state Predicts outcomes Remains consistent on re-measurement Provides actionable insight Noise Noise is information that: Reflects random variation Has no predictive power Fluctuates without meaningful change Distracts from actual patterns Why This Matters Most Data is Noise In any complex system, most variation is random. Sales fluctuate. Performance varies. Metrics bounce around. Most of this is noise. Acting on noise is a mistake. You&#39;ll see patterns that aren&#39;t there, make changes that aren&#39;t needed, and create volatility where stability is possible. Signal is Often Subtle Real signals are often small compared to noise. They require sustained attention to detect. An important trend might be a few percentage points hidden in wild monthly swings. Noise Looks Like Signal Human brains are pattern-recognition machines. We see patterns even where none exist. That face in the clouds, that trend in the data: probably noise. Sources of Noise Random Variation Every process has inherent variability. Temperature, timing, human attention: these fluctuate randomly. Implication: Expect variation. Don&#39;t treat every fluctuation as meaningful. Measurement Error The act of measuring introduces error. Different people measure differently. Instruments have precision limits. Implication: Understand your measurement uncertainty. Don&#39;t trust precision you can&#39;t justify. Sampling Effects When you measure a subset, you get a different result than you would from the whole. Implication: Larger samples reduce noise. Single data points are almost pure noise. Reporting Bias What gets reported isn&#39;t representative. People report what&#39;s interesting, unusual, or makes them look good. Implication: Ask what&#39;s not being reported. Seek boring data. Detecting Signal Persistence Signal persists over time. Noise fluctuates. Is this pattern consistent across multiple time periods? Does it survive changes in measurement approach? Would you expect to see it again if you re-measured? Magnitude Significant signals are usually large relative to typical variation. How big is this compared to normal fluctuation? Is it outside the range of expected randomness? Would you notice it without looking for it? Mechanism Real signals have explanations. Noise is random. Can you explain why this pattern exists? Does the explanation make sense given what you know? Would the pattern persist if the explanation were wrong? Convergence Multiple independent sources that agree suggest signal. Do different data sources tell the same story? Do different analysis methods reach the same conclusion? Do multiple observers see the same pattern? Tools for Separation Statistical Process Control Track metrics over time with control limits. Changes within limits are noise. Changes outside limits are signals worth investigating. Trend Lines Fit a line through noisy data. The line is your best estimate of signal. Deviations from the line are noise. Moving Averages Smooth out noise by averaging over a window. The moving average shows the underlying trend while individual points contain noise. Root Cause Correlation When signal is suspected, trace back to causes. If you can find a cause, it&#39;s more likely signal. If you can&#39;t, it might be noise. Common Mistakes Over-Fitting Seeing patterns in noise because you&#39;re looking too hard. More data points make it easier to find coincidences. Fix: Ask &quot;Would I predict this pattern going forward?&quot; Under-Fitting Dismissing real signals as noise because they&#39;re subtle or uncomfortable. Fix: Ask &quot;What evidence would convince me this is signal?&quot; Premature Pattern Matching Declaring a pattern on insufficient data. Fix: Wait for more data. Require patterns to persist before acting. Treating All Data Equally Averaging high-quality data with low-quality data, or mixing reliable sources with unreliable ones. Fix: Weight data by reliability. Separate sources by quality. Application to Diagnosis When investigating problems: Collect more data than you think you need. Signal emerges from volume. Look for persistent patterns. One data point is noise. Triangulate sources. Signal appears across multiple measures. Test explanations. If you can&#39;t explain why, it might be noise. Act on signal, ignore noise. But be willing to revise as data accumulates. In a noisy world, the ability to find signal is a superpower. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Signal vs Noise Not all information is equal. Signal is information that tells you something true about reality. Noise is information that doesn&#39;t. The ability to distinguish between them is fundamental to diagnosis. The Distinction Signal Signal is information that: Reflects actual state Predicts outcomes Remains consistent on re-measurement Provides actionable insight Noise Noise is information that: Reflects random variation Has no predictive power Fluctuates without meaningful change Dis","category":"Wiki"},{"url":"wiki/concepts/systems-thinking.html","title":"Systems Thinking","description":"Systems thinking is a way of seeing the world as interconnected patterns rather than isolated events. It focuses on relationships, feedback, and emergence rathe","headings":["Systems Thinking Systems thinking is a way of seeing the world as interconnected patterns rather than isolated events. It focuses on relationships, feedback, and emergence rather than linear cause and effect. The Shift Event-Level Thinking Most problem-solving operates at the event level: &quot;Sales dropped this quarter&quot; ‚Üí &quot;Run a promotion&quot; &quot;Server crashed&quot; ‚Üí &quot;Restart the server&quot; &quot;Employee quit&quot; ‚Üí &quot;Hire a replacement&quot; This is reactive. It treats symptoms. Problems recur. Systems-Level Thinking Systems thinking looks deeper: &quot;Sales dropped&quot; ‚Üí &quot;What market dynamics are shifting? What feedback loop is reinforcing the decline?&quot; &quot;Server crashed&quot; ‚Üí &quot;What load pattern caused this? What architectural constraint made it vulnerable?&quot; &quot;Employee quit&quot; ‚Üí &quot;What about our culture, compensation, or management made leaving attractive?&quot; This is proactive. It addresses root causes. Problems get solved. Core Principles Everything is Connected In a system, components influence each other. Change one thing, and ripples propagate. There are no isolated variables. Implication: Consider second-order effects. Ask &quot;and then what?&quot; until you&#39;ve traced the consequences. Structure Drives Behavior The way a system is organized determines how it behaves. The same people in different structures will produce different results. Implication: If you want different behavior, change the structure. Don&#39;t just blame the people. Feedback Rules Everything Systems are governed by feedback loops, both reinforcing and balancing. Understand the loops, understand the system. See Feedback Loop Analysis . Implication: Look for loops. When you find a persistent problem, there&#39;s probably a loop maintaining it. Emergence Happens The behavior of a system is often more than the sum of its parts. Properties emerge from interactions that can&#39;t be predicted from components alone. Implication: You can&#39;t fully understand a system by analyzing its components in isolation. Delays Obscure Causation In systems, causes and effects are often separated by time. This makes learning from experience difficult and interventions hard to evaluate. Implication: Be patient. Look for delayed effects. Don&#39;t assume absence of immediate result means absence of effect. System Archetypes Certain patterns appear repeatedly across different systems: Fixes That Fail A quick fix solves the symptom but ignores the root cause. The problem returns, often worse. Structure: Symptom ‚Üí Fix ‚Üí Relief (delay) ‚Üí Side effect ‚Üí Worse symptom Example: Overtime to meet deadlines ‚Üí Short-term success ‚Üí Fatigue ‚Üí Lower productivity ‚Üí More overtime needed Shifting the Burden An addiction-like pattern where symptomatic solutions undermine fundamental solutions. Structure: Problem ‚Üí Symptomatic solution + Fundamental solution ‚Üí Symptomatic solution is easier ‚Üí Dependency develops ‚Üí Fundamental solution atrophies Example: Knowledge gap ‚Üí Hire consultants + Train staff ‚Üí Consultants are faster ‚Üí Dependency on consultants ‚Üí Internal capability never develops Limits to Growth Initial success encounters constraints that slow and eventually stop growth. Structure: Growth ‚Üí Success ‚Üí Constraint activated ‚Üí Growth slows ‚Üí (If constraint not addressed) Growth stops Example: Startup grows ‚Üí More customers ‚Üí Support quality drops ‚Üí Customer complaints ‚Üí Reputation damage ‚Üí Growth stalls Tragedy of the Commons Individual rational actions deplete a shared resource. Structure: Individual benefit ‚Üí Resource use ‚Üí (Many individuals) ‚Üí Resource depletion ‚Üí Reduced individual benefit Example: Everyone optimizes their department ‚Üí Shared resources (IT, budget, attention) are overused ‚Üí Conflict and scarcity ‚Üí Everyone worse off Applying Systems Thinking Step 1: Define the System Boundary What&#39;s in? What&#39;s out? Boundaries are always somewhat arbitrary, but you need them to analyze. Step 2: Identify Components What are the major elements? Don&#39;t go too detailed too early. Step 3: Map Relationships How do components influence each other? Draw arrows. Note whether relationships are reinforcing (+) or balancing (-). Step 4: Find the Loops Trace circular patterns. Identify whether they&#39;re reinforcing or balancing. Note delays. Step 5: Look for Leverage Where can small interventions produce large effects? Usually at loop junctions or delay points. Step 6: Test Interventions Before implementing, think through how the system will respond. Will other loops counteract your intervention? Common Mistakes Focusing on Events Getting caught in the immediate rather than the structural. Events are symptoms; system structure is the cause. Linear Thinking Assuming A ‚Üí B ‚Üí C without considering that C might influence A. Ignoring Delays Expecting immediate results and abandoning interventions too soon. Pushing on Resistance Fighting balancing loops instead of changing what they&#39;re balancing toward. Optimizing Parts Making individual components better without considering system-wide effects. Systems don&#39;t respond to effort. They respond to structure. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Systems Thinking Systems thinking is a way of seeing the world as interconnected patterns rather than isolated events. It focuses on relationships, feedback, and emergence rather than linear cause and effect. The Shift Event-Level Thinking Most problem-solving operates at the event level: &quot;Sales dropped this quarter&quot; ‚Üí &quot;Run a promotion&quot; &quot;Server crashed&quot; ‚Üí &quot;Restart the server&quot; &quot;Employee quit&quot; ‚Üí &quot;Hire a replacement&quot; This is reactive. It t","category":"Wiki"},{"url":"wiki/diagnostic-process.html","title":"The Diagnostic Process","description":"Every Fogsift engagement follows a consistent diagnostic process. The specific tools vary, but the structure remains the same.","headings":["The Diagnostic Process Every Fogsift engagement follows a consistent diagnostic process. The specific tools vary, but the structure remains the same. Phase 1: Intake Symptom Collection We start by gathering every symptom, complaint, and observation. No filtering. No prioritization yet. Just collection. Key questions: What exactly is happening? When did you first notice it? Who noticed it first? What has been tried so far? Stakeholder Mapping Who cares about this problem? Who is affected? Who has information? We map the stakeholder landscape before we start investigating. Constraint Identification What can&#39;t change? What&#39;s off-limits? Understanding constraints early prevents wasted effort on solutions that can&#39;t be implemented. Phase 2: Investigation Trace Protocol We follow the TRACE Protocol to systematically investigate the problem: T arget the symptom R ecord the evidence A nalyze the chain C hallenge assumptions E xpose the root Evidence Gathering We collect data, documents, interviews, and observations. Everything gets documented. Nothing is too small to note. Pattern Recognition As evidence accumulates, patterns emerge. We look for: Recurring failures Common factors across incidents Timing correlations Process gaps Phase 3: Analysis Causal Chain Mapping We build a visual map of cause and effect, tracing from symptoms back to origins. This reveals: Where the chain breaks Where multiple causes converge Where interventions will be most effective Hypothesis Testing We don&#39;t just guess. We form hypotheses and test them against the evidence. If the evidence doesn&#39;t support the hypothesis, we revise. Root Cause Identification The root cause is the point where intervention will prevent recurrence. It&#39;s rarely the first thing you think of, and almost never &quot;human error.&quot; Phase 4: Recommendations Solution Design We design solutions that address the root cause, not just the symptoms. Good solutions are: Specific and actionable Proportional to the problem Within the organization&#39;s constraints Sustainable without ongoing intervention Implementation Roadmap We provide a clear sequence of steps, with dependencies mapped and quick wins identified. The roadmap includes: What to do first What can be done in parallel What requires sequential completion How to measure progress Risk Assessment Every solution has risks. We identify them upfront: What could go wrong? What are the early warning signs? What&#39;s the fallback plan? Phase 5: Transfer Documentation We document everything: the investigation, the findings, the recommendations, and the reasoning. This documentation becomes part of your organizational knowledge. Training We ensure your team understands not just what to do, but why . This enables them to adapt the solution and handle similar problems in the future. Follow-up We check in after implementation to verify the solution is working and make adjustments if needed. The process is rigorous, but flexible. The goal is always the same: find the truth, fix the problem, transfer the knowledge. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"The Diagnostic Process Every Fogsift engagement follows a consistent diagnostic process. The specific tools vary, but the structure remains the same. Phase 1: Intake Symptom Collection We start by gathering every symptom, complaint, and observation. No filtering. No prioritization yet. Just collection. Key questions: What exactly is happening? When did you first notice it? Who noticed it first? What has been tried so far? Stakeholder Mapping Who cares about this problem? Who is affected? Who has","category":"Wiki"},{"url":"wiki/faq.html","title":"Frequently Asked Questions","description":"Fogsift is an independent consulting practice specializing in diagnostic problem-solving. We help organizations find the root causes of complex, ambiguous probl","headings":["Frequently Asked Questions General What is Fogsift? Fogsift is an independent consulting practice specializing in diagnostic problem-solving. We help organizations find the root causes of complex, ambiguous problems. What does &quot;Fogsift&quot; mean? Fog represents the confusion, ambiguity, and noise that surrounds complex problems. We sift through that fog to find clarity. Who runs Fogsift? Christopher Tavolazzi. Background spans manufacturing diagnostics, process engineering, quality systems, and strategic consulting. Engagement How do I know if I need Fogsift? You might benefit from our help if: You&#39;ve tried multiple solutions and the problem persists You&#39;re not sure what the actual problem is Your internal teams disagree about the cause The &quot;obvious&quot; fix didn&#39;t work You need an outside perspective What industries do you work with? We work across industries because diagnostic principles are universal. Past engagements have included manufacturing, logistics, software development, healthcare operations, and professional services. How long do engagements take? It depends on the problem: Diagnostic sessions: 2-4 hours Deep dives: 1-2 weeks Complex investigations: 4-8 weeks Retainer relationships: Ongoing What does it cost? We price based on complexity and duration, not billable hours. We&#39;ll give you a fixed price before we start. Do you work remotely? Yes. Most diagnostic work can be done remotely through video calls, document review, and structured interviews. Some engagements benefit from on-site observation. Process What happens in the first conversation? We talk about your situation. What&#39;s going on? What have you tried? What constraints exist? By the end, we&#39;ll both know whether it makes sense to work together. How do you maintain confidentiality? Everything shared with us stays confidential. We never share specifics about engagements, and any case studies are anonymized and approved by the client. What if we disagree with your findings? Our job is to find the truth, not to tell you what you want to hear. We&#39;ll present our evidence and reasoning. You might have context we don&#39;t. Disagreement is productive if it leads to better understanding. Do you implement solutions or just recommend them? We primarily diagnose and recommend. Implementation is usually done by your team. We can advise during implementation and help troubleshoot if things don&#39;t go as planned. Results What&#39;s your success rate? We don&#39;t track &quot;success rate&quot; because that metric is meaningless without context. What we can say: we&#39;ve never failed to find the root cause. Whether organizations act on our findings is another matter. Can you guarantee results? We guarantee rigorous investigation and honest findings. We can&#39;t guarantee you&#39;ll like what we find, or that you&#39;ll implement our recommendations. What if the problem comes back? If we identified the root cause correctly and the solution was implemented properly, the problem shouldn&#39;t recur. If it does, we&#39;ll investigate why at no additional cost. Weird Questions What&#39;s the strangest problem you&#39;ve solved? Can&#39;t share specifics due to confidentiality, but let&#39;s just say not all problems are what they appear to be. Do you work on personal problems, not just business ones? The same diagnostic principles apply. If you&#39;ve got a weird personal problem that defies simple solutions, we can talk about it. What if I don&#39;t have a specific problem, I just want to talk? Use the Weird Question Hotline . It exists for exactly this purpose. Still have questions? Get in touch. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Frequently Asked Questions General What is Fogsift? Fogsift is an independent consulting practice specializing in diagnostic problem-solving. We help organizations find the root causes of complex, ambiguous problems. What does &quot;Fogsift&quot; mean? Fog represents the confusion, ambiguity, and noise that surrounds complex problems. We sift through that fog to find clarity. Who runs Fogsift? Christopher Tavolazzi. Background spans manufacturing diagnostics, process engineering, quality systems","category":"Wiki"},{"url":"wiki/field-notes/001-map-territory.html","title":"Field Note: The Map Is Not The Territory","description":"---","headings":["Field Note: The Map Is Not The Territory Date: 2025-01-14 Sector: STRATEGY Read Time: 2 minutes Most organizations confuse their organizational chart with their actual communication network. When we deploy the Trace protocol, we find the critical node is often a Scheduler in a basement office. Not the VP. Not the Director. The person who actually knows where everything is. The Observation Org charts show reporting lines. They don&#39;t show: Who actually gets called when something breaks Who knows where the bodies are buried Who can get things done without a meeting These informal networks are the real operating system of an organization. The org chart is just the marketing brochure. The Implication When diagnosing organizational problems, start by mapping the actual information flow: Who gets CC&#39;d on everything? That&#39;s a power node. Who do people call before escalating? That&#39;s a trust node. Who&#39;s in every meeting? That might be a bottleneck. The Action Next time you&#39;re troubleshooting a process failure, don&#39;t look at the org chart. Look at the email threads. Look at the Slack channels. Look at who&#39;s standing at whose desk. The map is not the territory. Related: Root Cause Analysis Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Field Note: The Map Is Not The Territory Date: 2025-01-14 Sector: STRATEGY Read Time: 2 minutes Most organizations confuse their organizational chart with their actual communication network. When we deploy the Trace protocol, we find the critical node is often a Scheduler in a basement office. Not the VP. Not the Director. The person who actually knows where everything is. The Observation Org charts show reporting lines. They don&#39;t show: Who actually gets called when something breaks Who kno","category":"Wiki"},{"url":"wiki/field-notes/002-precision-accuracy.html","title":"Field Note: Precision vs Accuracy","description":"---","headings":["Field Note: Precision vs Accuracy Date: 2025-01-08 Sector: FABRICATION Read Time: 4 minutes In CNC machining, precision and accuracy are different things. Understanding this distinction changes how you diagnose problems, in manufacturing and everywhere else. The Definitions Precision is repeatability. Can you hit the same spot every time? Accuracy is correctness. Is that spot the right spot? You can be precise without being accurate (hitting the same wrong spot every time). You can be accurate without being precise (hitting near the right spot but inconsistently). The Manufacturing Example A CNC mill that consistently cuts 0.002&quot; too deep has a precision problem and an accuracy problem. But they have different causes: Precision issues ‚Üí mechanical wear, thermal expansion, vibration Accuracy issues ‚Üí calibration, tool measurement, coordinate systems Fixing vibration won&#39;t fix a calibration error. Recalibrating won&#39;t fix a worn bearing. The Strategic Parallel Organizations have the same distinction: Precise but inaccurate : Consistent processes that produce the wrong outcome Accurate but imprecise : Right goals, inconsistent execution Neither : Chaos The Diagnostic Question When something&#39;s not working, ask: Is it consistently wrong? (Precision is fine, accuracy is off) Is it inconsistently wrong? (Accuracy might be fine, precision is off) Is it randomly wrong? (Both are off, or you&#39;re measuring wrong) The answer tells you where to look. The Action Before you start fixing, measure twice: Are you hitting the same spot? (Precision check) Is that spot where you intended? (Accuracy check) Different problems. Different solutions. This applies to: budgets, schedules, quality metrics, hiring, strategy execution, and anything else you measure. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Field Note: Precision vs Accuracy Date: 2025-01-08 Sector: FABRICATION Read Time: 4 minutes In CNC machining, precision and accuracy are different things. Understanding this distinction changes how you diagnose problems, in manufacturing and everywhere else. The Definitions Precision is repeatability. Can you hit the same spot every time? Accuracy is correctness. Is that spot the right spot? You can be precise without being accurate (hitting the same wrong spot every time). You can be accurate w","category":"Wiki"},{"url":"wiki/field-notes/003-entropy.html","title":"Field Note: Entropy","description":"---","headings":["Field Note: Entropy Date: 2024-12-22 Sector: SYSTEMS Read Time: 3 minutes Chaos is the default state. Order requires energy injection. If you stop pushing, the system decays. The Law The Second Law of Thermodynamics, translated for business: Every system tends toward disorder unless energy is continuously applied to maintain order. Your documentation will rot. Your processes will drift. Your culture will dilute. Not because anyone wants it to. Entropy is the universe&#39;s default setting. The Observation Organizations that stop actively maintaining their systems don&#39;t stay the same. They get worse: Undocumented processes don&#39;t stay undocumented. They become inconsistent processes. Unclear ownership doesn&#39;t stay unclear. It becomes contested ownership. Deferred maintenance doesn&#39;t stay deferred. It becomes emergency maintenance. The Math Entropy is cheap. Order is expensive. But disorder is most expensive. The cost curve looks like this: Prevention : $1 (continuous small investments) Correction : $10 (periodic fixes when drift is noticed) Crisis : $100 (emergency intervention when systems fail) Most organizations budget for correction and pay for crisis. The Action Build maintenance into the system: Scheduled reviews : Don&#39;t wait for problems to surface Forcing functions : Make decay visible before it&#39;s critical Ownership rituals : Someone must be responsible for fighting entropy You can&#39;t stop entropy. But you can budget for it. The fight against entropy is not optional. It&#39;s the cost of having systems at all. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Field Note: Entropy Date: 2024-12-22 Sector: SYSTEMS Read Time: 3 minutes Chaos is the default state. Order requires energy injection. If you stop pushing, the system decays. The Law The Second Law of Thermodynamics, translated for business: Every system tends toward disorder unless energy is continuously applied to maintain order. Your documentation will rot. Your processes will drift. Your culture will dilute. Not because anyone wants it to. Entropy is the universe&#39;s default setting. The O","category":"Wiki"},{"url":"wiki/field-notes/004-bottlenecks.html","title":"Field Note: Finding the Bottleneck","description":"---","headings":["Field Note: Finding the Bottleneck Date: 2025-01-20 Sector: OPERATIONS Read Time: 4 minutes Every system has a bottleneck. The constraint that limits throughput. The thing that, if you improved it, would improve everything. The thing that, if you ignore it, makes all other improvements irrelevant. The Observation Client had a manufacturing operation. They&#39;d invested heavily in automation on the production floor. State-of-the-art equipment. Impressive cycle times. And yet, output was flat. Everyone had theories: &quot;We need more floor space&quot; &quot;The equipment isn&#39;t running at capacity&quot; &quot;We need more shifts&quot; We walked the floor. Watched the flow. Asked one question at every station: &quot;What are you waiting for?&quot; The bottleneck wasn&#39;t on the production floor. It was in the quality lab. Every batch needed certification. The lab was understaffed, working overtime, and still couldn&#39;t keep up. Production sat waiting. All that automation produced material that queued for inspection. The Principle The Theory of Constraints: A chain is only as strong as its weakest link. A system only produces as fast as its slowest process. Investing anywhere except the bottleneck is waste. No matter how fast the other stations get, the bottleneck determines output. If inspection can handle 100 units per day, you can never ship more than 100 units per day, no matter how much production capacity you have. Finding Your Bottleneck Method 1: Follow the Queue Where does work pile up? Where do people wait? Where do things sit before moving to the next step? That&#39;s probably the bottleneck. Method 2: Calculate Capacity For each step in your process, calculate how much it can handle per unit time. The step with the lowest capacity is the bottleneck. Method 3: Ask the People The people doing the work usually know. Ask: &quot;What&#39;s the biggest barrier to getting more done?&quot; Listen without defending. What to Do With the Bottleneck Once you&#39;ve found it: Exploit it: Make sure the bottleneck is never starved for input or blocked from output. It should never wait. Subordinate to it: All other processes should operate at the pace the bottleneck can handle. Producing faster upstream just creates inventory. Elevate it: If you need more capacity, invest in the bottleneck first. Not elsewhere. Repeat: Once you fix this bottleneck, something else becomes the bottleneck. Find it and start again. The Resolution The client didn&#39;t need more production equipment. They needed two more lab technicians and a faster testing protocol. Cost: ~$200K per year in salary Result: 40% increase in output ROI: Measured in weeks The automation investment was fine. It just couldn&#39;t realize its value until the bottleneck moved. The Meta-Lesson The bottleneck is often not where you expect it. And it&#39;s almost never where the organization is investing. High-performing operations don&#39;t ask &quot;how do we improve?&quot; They ask &quot;what&#39;s the bottleneck?&quot; and then improve only that. Efficiency everywhere is waste. Efficiency at the bottleneck is leverage. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Field Note: Finding the Bottleneck Date: 2025-01-20 Sector: OPERATIONS Read Time: 4 minutes Every system has a bottleneck. The constraint that limits throughput. The thing that, if you improved it, would improve everything. The thing that, if you ignore it, makes all other improvements irrelevant. The Observation Client had a manufacturing operation. They&#39;d invested heavily in automation on the production floor. State-of-the-art equipment. Impressive cycle times. And yet, output was flat. Ev","category":"Wiki"},{"url":"wiki/field-notes/005-tribal-knowledge.html","title":"Field Note: Tribal Knowledge","description":"---","headings":["Field Note: Tribal Knowledge Date: 2025-01-06 Sector: MANUFACTURING Read Time: 3 minutes The most critical information in an organization is often stored in heads, not systems. The Observation Client had a quality problem. Intermittent defects. No obvious pattern. We ran the standard diagnostics: reviewed procedures, checked equipment calibration, analyzed process parameters. Everything looked fine on paper. Then we spent a day on the shop floor. Watched an operator set up a machine. He made an adjustment that wasn&#39;t in the procedure. A slight tweak to the positioning. &quot;What&#39;s that for?&quot; &quot;Oh, this machine drifts. If you don&#39;t offset by about two thousandths, you get rejects.&quot; &quot;Is that documented anywhere?&quot; &quot;No, you just have to know.&quot; That adjustment was the difference between good parts and scrap. It was known to three operators. When any of them were absent, defect rates spiked. The Problem with Tribal Knowledge It&#39;s Fragile When the person who knows leaves, takes vacation, or gets sick, the knowledge goes with them. Organizations that run on tribal knowledge are one resignation away from crisis. It&#39;s Inconsistent Different people &quot;know&quot; different things. Their personal versions of the unwritten rules conflict. Quality becomes dependent on who&#39;s working that day. It&#39;s Invisible You can&#39;t improve what you can&#39;t see. Tribal knowledge exists outside formal systems. It doesn&#39;t show up in audits, process maps, or training materials. It&#39;s organizational dark matter. It&#39;s Often Wrong What one generation of workers figured out gets passed down, but the reasoning is lost. The tribal knowledge might have been correct once, but conditions changed. Now it&#39;s superstition masquerading as expertise. Finding Tribal Knowledge Watch, Don&#39;t Read The gap between documented procedure and actual practice is where tribal knowledge lives. Observe what people actually do. Note the differences. Ask the Right Questions &quot;Is there anything you do that isn&#39;t in the procedure?&quot; &quot;What do new people get wrong until they learn the tricks?&quot; &quot;If you&#39;re out sick, what goes wrong?&quot; &quot;What would you tell your replacement that isn&#39;t written down?&quot; Follow the Failures When defects or problems occur, ask &quot;who was working?&quot; Patterns in personnel often point to tribal knowledge that some have and others don&#39;t. What to Do About It Document It Once you find tribal knowledge, write it down. Add it to procedures, training materials, or work instructions. Convert head-knowledge to system-knowledge. Verify It Just because someone &quot;knows&quot; something doesn&#39;t make it true. Test tribal knowledge. Is that adjustment actually necessary? Does that workaround actually work? Challenge the folklore. Reward Sharing Tribal knowledge persists because it feels like power. Knowing what others don&#39;t creates job security. Change the incentives. Reward people for documenting and sharing their knowledge. Systematize It Where possible, build tribal knowledge into the system itself. Error-proofing, automated adjustments, checklists: these eliminate dependence on individual knowledge. The Resolution We documented the machine offset and a dozen similar undocumented practices. Updated procedures. Built verification into the setup checklist. Defect rate dropped 60%. More importantly, it became consistent regardless of which operator was on shift. The Takeaway The most dangerous knowledge isn&#39;t the knowledge you don&#39;t have. It&#39;s the knowledge you don&#39;t know you&#39;re depending on. If it&#39;s not documented, it&#39;s not a process. It&#39;s a person. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Field Note: Tribal Knowledge Date: 2025-01-06 Sector: MANUFACTURING Read Time: 3 minutes The most critical information in an organization is often stored in heads, not systems. The Observation Client had a quality problem. Intermittent defects. No obvious pattern. We ran the standard diagnostics: reviewed procedures, checked equipment calibration, analyzed process parameters. Everything looked fine on paper. Then we spent a day on the shop floor. Watched an operator set up a machine. He made an ","category":"Wiki"},{"url":"wiki/field-notes/006-incentive-alignment.html","title":"Field Note: Incentive Alignment","description":"---","headings":["Field Note: Incentive Alignment Date: 2024-12-15 Sector: STRATEGY Read Time: 5 minutes If you want to understand behavior, look at incentives. If you want to change behavior, change incentives. Most organizational dysfunction is incentive dysfunction in disguise. The Observation Client had a sales problem. Revenue was stagnant despite aggressive targets. The sales team was working hard. Pipeline looked full. But deals weren&#39;t closing. Leadership blamed: Market conditions Competitor pricing Sales team competence We looked at incentive structures. Sales was compensated on closed deals. Standard stuff. But the bonus kicker required hitting quota by quarter-end. Miss by one deal, no bonus. What happens when you&#39;re close to quota on the last day of the quarter? You push. You discount. You promise things that shouldn&#39;t be promised. You close deals that shouldn&#39;t be closed. And the next quarter starts with angry customers, unrealistic expectations, and a depleted pipeline because everything got pulled forward. The incentive was misaligned. It rewarded closing deals, not building business. The Principle &quot;Never, ever, think about something else when you should be thinking about the power of incentives.&quot; - Charlie Munger People respond to incentives. They do what they&#39;re rewarded for and avoid what they&#39;re punished for. If you don&#39;t like the behavior, check the incentives. How Incentives Misalign Short-Term vs Long-Term Rewarding this quarter&#39;s results at the expense of next year&#39;s health. Examples: Sales bonuses that encourage deal-pulling Cost-cutting that reduces training investment Production targets that sacrifice maintenance Individual vs Collective Rewarding individual performance at the expense of team success. Examples: Commission structures that discourage collaboration Performance rankings that create internal competition Recognition systems that highlight stars over teams Metrics vs Outcomes Rewarding the measurable proxy instead of the actual goal. Examples: Call centers rewarded on call duration, not resolution Teachers rewarded on test scores, not learning Engineers rewarded on lines of code, not working software Activity vs Results Rewarding effort instead of outcomes. Examples: Points for attending meetings Recognition for hours worked Rewards for activities regardless of impact Diagnosing Incentive Problems Follow the Money What gets rewarded with compensation, promotion, and recognition? That&#39;s what people will do. Find the Workarounds When people game the system, they&#39;re revealing the gap between stated goals and actual incentives. The workaround is a symptom; the misalignment is the cause. Ask &quot;Why Would Smart People Do This?&quot; If smart people are doing something that seems dumb, they&#39;re probably responding rationally to incentives you haven&#39;t understood. Map the Trade-offs Every incentive creates trade-offs. What behavior does the incentive encourage at the margin? What gets sacrificed? Fixing Incentive Problems Align Time Horizons Include long-term metrics. Clawback short-term bonuses if long-term results don&#39;t follow. Create continuity between periods. Balance Individual and Collective Mix individual rewards with team and organizational components. Make collaboration visibly rewarded. Measure Outcomes, Not Proxies Get closer to what you actually want. If you can&#39;t measure the outcome directly, at least use multiple proxies that triangulate. Build in Quality Checks If you reward quantity, add quality gates. If you reward speed, add accuracy requirements. Test for Perverse Incentives Before implementing, ask: &quot;How could someone maximize this metric in ways we wouldn&#39;t want?&quot; The Resolution We redesigned the comp structure: Extended bonus period to six months Added customer retention component Included deal quality metrics (margin, contract terms) Created team-based accelerators Quarter-end chaos subsided. Customer complaints dropped. And revenue actually increased because the team was building sustainable relationships instead of chasing quarterly bonuses. The Meta-Lesson People aren&#39;t problems. Incentives are problems. Change the incentives, change the behavior. When you find people doing something that doesn&#39;t make sense, don&#39;t conclude they&#39;re stupid or malicious. Conclude that you don&#39;t understand their incentives. Show me the incentive and I&#39;ll show you the outcome. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Field Note: Incentive Alignment Date: 2024-12-15 Sector: STRATEGY Read Time: 5 minutes If you want to understand behavior, look at incentives. If you want to change behavior, change incentives. Most organizational dysfunction is incentive dysfunction in disguise. The Observation Client had a sales problem. Revenue was stagnant despite aggressive targets. The sales team was working hard. Pipeline looked full. But deals weren&#39;t closing. Leadership blamed: Market conditions Competitor pricing S","category":"Wiki"},{"url":"wiki/field-notes/007-documentation-debt.html","title":"Field Note: Documentation Debt","description":"---","headings":["Field Note: Documentation Debt Date: 2024-11-28 Sector: ENGINEERING Read Time: 4 minutes Technical debt is well understood. Documentation debt is its quieter, more insidious cousin. The Observation Client was struggling with onboarding. New engineers took months to become productive. Everyone blamed the complexity of the codebase. We interviewed recent hires. Asked what slowed them down. &quot;There&#39;s a wiki, but half the pages are outdated.&quot; &quot;I spent three days figuring out something that took my mentor five minutes to explain.&quot; &quot;The README says one thing, but the code does something else.&quot; &quot;I was afraid to ask because everyone seems so busy.&quot; The problem wasn&#39;t code complexity. It was documentation debt. The system had evolved. The documentation hadn&#39;t. What was written was wrong. What was right was unwritten. What Is Documentation Debt? Documentation debt accumulates when: Docs aren&#39;t created when systems are built Docs aren&#39;t updated when systems change Knowledge lives in people&#39;s heads instead of accessible sources Outdated docs are left in place, misleading future readers Like technical debt, documentation debt compounds. The longer you wait, the harder it is to catch up. The Cost of Documentation Debt Onboarding Time Every new person has to reconstruct the knowledge that could have been documented. Multiply this by every hire, and the waste is staggering. Expert Dependency When only certain people know how things work, they become bottlenecks. Everything flows through them. They can&#39;t take vacation. They can&#39;t work on new things. Repeated Mistakes Without documentation, each person discovers the same pitfalls independently. Lessons don&#39;t transfer. Mistakes repeat. Decision Paralysis When no one knows why things are the way they are, no one wants to change them. &quot;It might be like that for a reason.&quot; Tribal Knowledge Risk See Field Note: Tribal Knowledge . Undocumented knowledge walks out the door when people leave. Where Documentation Debt Hides Architecture Decisions Why was it built this way? What alternatives were considered? What are the trade-offs? This context is almost never written down. Configuration What do these settings mean? Why are they set to these values? What happens if you change them? Procedures How do you deploy? How do you recover from failure? How do you handle the edge cases? History What did we try before? What didn&#39;t work? What constraints existed that might have changed? Paying Down Documentation Debt Make It Part of the Work Documentation isn&#39;t a separate task. It&#39;s part of completing the work. A feature isn&#39;t done until it&#39;s documented. Write for the Future Write for someone who doesn&#39;t know what you know. Your future self qualifies. Capture Decisions When you make a significant decision, write down: What you decided What alternatives you considered Why you chose this option What would make you reconsider Kill Zombie Docs Outdated documentation is worse than no documentation. It misleads. Either update it or delete it. Create Forcing Functions Code reviews that check for doc updates Onboarding feedback that identifies gaps Regular doc audits Ownership assignment for doc sections The Resolution We implemented a documentation sprint. Two weeks of capturing the critical knowledge that was trapped in heads. More importantly, we changed the process: PRs now require doc updates for user-facing changes Architecture Decision Records (ADRs) for significant choices Onboarding includes creating documentation as you learn Doc ownership rotates quarterly Six months later, onboarding time had halved. And the senior engineers weren&#39;t getting interrupted as often. The Takeaway Documentation isn&#39;t overhead. It&#39;s infrastructure. Every hour not spent documenting is borrowed from the future. Eventually, the debt comes due. If it isn&#39;t written down, you&#39;ll explain it again. And again. And again. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Field Note: Documentation Debt Date: 2024-11-28 Sector: ENGINEERING Read Time: 4 minutes Technical debt is well understood. Documentation debt is its quieter, more insidious cousin. The Observation Client was struggling with onboarding. New engineers took months to become productive. Everyone blamed the complexity of the codebase. We interviewed recent hires. Asked what slowed them down. &quot;There&#39;s a wiki, but half the pages are outdated.&quot; &quot;I spent three days figuring out someth","category":"Wiki"},{"url":"wiki/frameworks/constraint-mapping.html","title":"Constraint Mapping","description":"Constraint mapping identifies and visualizes the boundaries within which a solution must operate. It prevents wasted effort on solutions that can't be implement","headings":["Constraint Mapping Constraint mapping identifies and visualizes the boundaries within which a solution must operate. It prevents wasted effort on solutions that can&#39;t be implemented and reveals hidden degrees of freedom. The Principle Every problem exists within a constraint envelope. Understand the envelope before you design the solution. Constraints aren&#39;t obstacles. They&#39;re design parameters. Once you know them, they guide you toward viable solutions. Types of Constraints Hard Constraints Absolute limits that cannot be violated. Examples: Legal requirements Physical laws Non-negotiable deadlines Budget caps Safety requirements Characteristic: Breaking them isn&#39;t an option, no matter how good the solution. Soft Constraints Strong preferences that can be violated under sufficient justification. Examples: Internal policies Historical practices Stakeholder preferences Resource availability Timeline targets Characteristic: Can be challenged, negotiated, or waived if the tradeoff is worth it. Hidden Constraints Limits that aren&#39;t explicitly stated but become apparent during implementation. Examples: Political dynamics Unwritten rules Legacy system dependencies Cultural norms Institutional knowledge gaps Characteristic: Often the cause of &quot;good ideas&quot; that fail to launch. Self-Imposed Constraints Limits we assume exist but don&#39;t actually. Examples: &quot;We&#39;ve always done it this way&quot; &quot;They&#39;ll never approve that&quot; &quot;That&#39;s not possible with our tools&quot; &quot;The team wouldn&#39;t accept that change&quot; Characteristic: Often invisible until challenged. The Mapping Process Step 1: Gather Stated Constraints Ask stakeholders directly: What can&#39;t change? What&#39;s non-negotiable? What limits exist? What has been tried and rejected? Document everything, even constraints that seem obvious. Step 2: Classify by Type For each constraint, determine: Is it hard or soft? Is it explicit or hidden? Is it real or self-imposed? Step 3: Test Validity For soft and self-imposed constraints, ask: Who says this is a constraint? What evidence supports it? What would it take to change it? What&#39;s the cost of violating it? You&#39;ll often find that &quot;constraints&quot; are actually preferences or outdated assumptions. Step 4: Map Dependencies Constraints interact. Understanding these dependencies reveals: Which constraints are load-bearing Which constraints can be moved together Where changing one constraint affects others Step 5: Identify Degrees of Freedom The space between constraints is your solution space. Map it: What can change? What can be combined? What can be sequenced differently? What can be eliminated? Visualization A constraint map can take several forms: Boundary Diagram Draw the solution space as an area, with constraints as boundaries. Hard constraints are solid lines. Soft constraints are dashed. Constraint Table Constraint Type Source Negotiable? Dependencies Q4 deadline Hard Board No Budget Existing platform Soft IT Yes, with justification Timeline Current team only Self-imposed Assumption Test with sponsor None Dependency Graph Show constraints as nodes and dependencies as arrows. Highlight constraints that affect many others. Common Patterns Over-Constrained Problems When constraints leave no viable solution space: Challenge soft constraints Test self-imposed constraints Look for creative interpretations Escalate genuine conflicts Under-Constrained Problems When too much is possible: Add design principles Define quality criteria Set optimization targets Prioritize ruthlessly Constraint Migration When stakeholders keep adding constraints after work begins: Trace new constraints to their source Document impact on solution space Force explicit tradeoff decisions Application Before designing solutions: Map all known constraints Test self-imposed constraints Identify hidden constraints through investigation Document the viable solution space Design solutions that fit within the envelope Understanding what you can&#39;t do clarifies what you can. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Constraint Mapping Constraint mapping identifies and visualizes the boundaries within which a solution must operate. It prevents wasted effort on solutions that can&#39;t be implemented and reveals hidden degrees of freedom. The Principle Every problem exists within a constraint envelope. Understand the envelope before you design the solution. Constraints aren&#39;t obstacles. They&#39;re design parameters. Once you know them, they guide you toward viable solutions. Types of Constraints Hard Con","category":"Wiki"},{"url":"wiki/frameworks/decision-matrix.html","title":"Decision Matrix","description":"A decision matrix is a structured approach to evaluating options against weighted criteria. It turns complex decisions into transparent, defensible choices.","headings":["Decision Matrix A decision matrix is a structured approach to evaluating options against weighted criteria. It turns complex decisions into transparent, defensible choices. When to Use It Use a decision matrix when: You have multiple viable options Multiple criteria matter Stakeholders have different priorities You need to document the rationale The decision is high-stakes or irreversible Don&#39;t use it when: There&#39;s an obvious choice Speed matters more than optimization You&#39;re using it to justify a decision you&#39;ve already made The Framework Step 1: Define Options List all viable options. Include &quot;do nothing&quot; if it&#39;s a real option. Exclude options that fail hard constraints. Good options are: Mutually exclusive (you can&#39;t do both) Collectively exhaustive (you&#39;ve covered the space) Concrete (you know what implementation looks like) Step 2: Define Criteria What factors matter for this decision? Criteria should be: Independent: Each criterion measures something different Measurable: You can evaluate options against them Relevant: They actually affect the outcome you care about Accepted: Stakeholders agree these are the right criteria Common criteria categories: Cost (upfront, ongoing, hidden) Risk (likelihood, impact, reversibility) Time (to implement, to realize value) Capability (what it enables) Alignment (with strategy, culture, constraints) Step 3: Weight Criteria Not all criteria matter equally. Assign weights that sum to 100%. Weighting methods: Direct assignment: Stakeholders agree on percentages Pairwise comparison: Compare criteria two at a time Point allocation: Give each stakeholder 100 points to distribute The conversation about weights is often more valuable than the weights themselves. It forces stakeholders to articulate what really matters. Step 4: Score Options Rate each option against each criterion. Use a consistent scale (1-5 or 1-10). Scoring guidelines: Define what each score means before you start Score one criterion at a time (not one option at a time) Use evidence where available Note assumptions and uncertainties Step 5: Calculate and Analyze Multiply each score by its weight and sum across criteria. But don&#39;t stop at the number. Analyze: How sensitive is the result to weight changes? Where are the biggest score differences? What assumptions drive the scores? Does the result match intuition? If not, why? Example Decision: Which project management tool to adopt? Criterion Weight Tool A Tool B Tool C Ease of use 30% 4 5 3 Integration 25% 5 3 4 Cost 20% 3 4 5 Scalability 15% 4 3 4 Support 10% 3 4 3 Weighted Score 3.95 3.85 3.75 Tool A wins, but barely. The decision isn&#39;t clear-cut, which suggests this might warrant more investigation. Common Pitfalls Analysis Paralysis The matrix is a tool for decision-making, not a substitute for it. At some point, you have enough information. Make the call. False Precision A score of 3.82 is not meaningfully different from 3.79. Don&#39;t let decimal places create false confidence. Gaming the Weights If you change the weights until your preferred option wins, you&#39;re not using a decision matrix. You&#39;re rationalizing. Ignoring Intuition If the matrix says Option A but your gut screams Option B, investigate. Your intuition might be detecting something the matrix missed. Forgetting Implementation The best option on paper is worthless if you can&#39;t implement it. Include implementation feasibility in your criteria. Variations Threshold Matrix Add a minimum acceptable score for each criterion. Options that fail any threshold are eliminated regardless of total score. Risk-Adjusted Matrix Score both expected outcome and worst-case outcome. Weight them based on risk tolerance. Multi-Stakeholder Matrix Let different stakeholders assign their own weights. Analyze where they agree and disagree. The matrix doesn&#39;t make the decision. It makes the decision process visible. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Decision Matrix A decision matrix is a structured approach to evaluating options against weighted criteria. It turns complex decisions into transparent, defensible choices. When to Use It Use a decision matrix when: You have multiple viable options Multiple criteria matter Stakeholders have different priorities You need to document the rationale The decision is high-stakes or irreversible Don&#39;t use it when: There&#39;s an obvious choice Speed matters more than optimization You&#39;re using i","category":"Wiki"},{"url":"wiki/frameworks/feedback-loops.html","title":"Feedback Loop Analysis","description":"Feedback loops are circular chains of cause and effect where the output of a system influences its own input. Understanding them is essential for diagnosing per","headings":["Feedback Loop Analysis Feedback loops are circular chains of cause and effect where the output of a system influences its own input. Understanding them is essential for diagnosing persistent problems and designing effective interventions. The Basics What is a Feedback Loop? A ‚Üí B ‚Üí C ‚Üí A The output (C) influences the input (A), which changes B, which changes C, which changes A again. The cycle continues. Two Types of Loops Reinforcing loops amplify change. They make things grow or decline exponentially. Success breeds success Debt creates more debt Panic causes more panic Growth enables more growth Balancing loops resist change. They stabilize systems around a target. Thermostat maintains temperature Hunger prompts eating Inventory triggers reordering Fatigue forces rest Why Loops Matter for Diagnosis Persistent Problems If a problem keeps coming back despite interventions, look for a reinforcing loop that&#39;s working against you. Example: High turnover Turnover increases workload on remaining staff Increased workload leads to burnout Burnout leads to more turnover Breaking this loop requires intervention at multiple points, not just hiring faster. Unexpected Resistance If a change doesn&#39;t stick, look for a balancing loop that&#39;s resisting it. Example: Process improvement New process is introduced Extra effort required to follow new process Under deadline pressure, people revert to old habits System returns to previous state The balancing loop around &quot;minimize effort under pressure&quot; defeats the change. Delayed Effects Loops often have delays. Today&#39;s cause produces tomorrow&#39;s effect, making the connection hard to see. Example: Quality investment Invest in quality ‚Üí improved products (6-month delay) Improved products ‚Üí higher customer satisfaction (3-month delay) Higher satisfaction ‚Üí more referrals (6-month delay) More referrals ‚Üí higher revenue (3-month delay) Higher revenue ‚Üí more investment capacity Total loop time: 18 months. In the meantime, the investment looks like pure cost. Analysis Process Step 1: Map the Variables Identify all the factors involved in the system. Don&#39;t worry about connections yet. Step 2: Trace the Connections For each variable, ask: &quot;What does this directly influence?&quot; Draw arrows from cause to effect. Label each arrow: + if an increase in the cause leads to an increase in the effect - if an increase in the cause leads to a decrease in the effect Step 3: Identify Loops Follow the arrows around. When you return to a starting point, you&#39;ve found a loop. Determine loop type: Count the negative (-) arrows in the loop Even number (including zero) = Reinforcing loop Odd number = Balancing loop Step 4: Find Delays For each connection, estimate the delay. Significant delays change how the loop behaves and how interventions should be designed. Step 5: Identify Leverage Points Where in the loop can you intervene? High leverage points: Where you can break a reinforcing loop that&#39;s causing harm Where you can strengthen a balancing loop that&#39;s maintaining dysfunction Where you can change the direction of an arrow Intervention Strategies Breaking Reinforcing Loops You don&#39;t need to break every link. Find the weakest point and intervene there. Example: For the turnover loop, possible interventions: Reduce workload impact (cross-training) Increase burnout resilience (support programs) Speed up replacement (hiring pipeline) Change the base state (proactive staffing) Modifying Balancing Loops To enable change, you need to shift what the loop is balancing toward. Example: For the process adoption loop, possible interventions: Change the target (make new process the expected default) Reduce resistance (make new process easier) Add accountability (create cost for reverting) Allow the transition (temporary performance dip expected) Adding New Loops Sometimes the solution is to create a new loop that counteracts the problematic one. Common Patterns The Fixes That Fail Problem occurs Quick fix applied Symptoms subside Root cause unaddressed Problem returns, often worse The quick fix creates a balancing loop that masks the problem without solving it. Shifting the Burden Problem occurs Symptomatic solution applied Side effect undermines fundamental solution Dependency on symptomatic solution grows Capability for fundamental solution atrophies Example: Outsourcing expertise instead of building it internally. Eroding Goals Performance falls short of goal Pressure to close the gap Goal is lowered instead of performance raised New goal becomes the standard Repeat The balancing loop works, but toward the wrong target. Systems resist change. Understanding why tells you where to push. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Feedback Loop Analysis Feedback loops are circular chains of cause and effect where the output of a system influences its own input. Understanding them is essential for diagnosing persistent problems and designing effective interventions. The Basics What is a Feedback Loop? A ‚Üí B ‚Üí C ‚Üí A The output (C) influences the input (A), which changes B, which changes C, which changes A again. The cycle continues. Two Types of Loops Reinforcing loops amplify change. They make things grow or decline expone","category":"Wiki"},{"url":"wiki/frameworks/trace-protocol.html","title":"The TRACE Protocol","description":"TRACE is our systematic approach to diagnostic investigation. It provides structure without being prescriptive, ensuring thorough investigation while remaining ","headings":["The TRACE Protocol TRACE is our systematic approach to diagnostic investigation. It provides structure without being prescriptive, ensuring thorough investigation while remaining adaptable to different problem types. The Framework T - Target the Symptom Before you can solve a problem, you need to define it precisely. Questions to answer: What exactly is happening? What should be happening instead? What is the gap between current and desired state? How do we measure the symptom? Common mistakes: Defining the problem too broadly (&quot;things are broken&quot;) Defining the symptom as a cause (&quot;we have a training problem&quot;) Accepting someone else&#39;s problem definition without verification Output: A clear, measurable symptom statement. R - Record the Evidence Systematic evidence collection prevents confirmation bias and ensures you don&#39;t miss important data. Evidence types: Documentary: Emails, reports, logs, metrics, procedures Testimonial: Interviews, observations, firsthand accounts Physical: Site observations, artifact inspection Temporal: Timelines, sequences, patterns over time Recording principles: Capture everything, filter later Note sources and dates Distinguish fact from interpretation Preserve original context Output: Organized evidence repository with clear sourcing. A - Analyze the Chain Map the causal chain from symptom to source. Process: Start with the symptom Ask &quot;what directly caused this?&quot; Document the cause Repeat until you reach a point where intervention is possible Tools: Five Whys Fishbone Diagrams Causal chain mapping Timeline analysis Warning signs you&#39;ve stopped too early: The cause is a person (&quot;John made an error&quot;) The cause is vague (&quot;communication breakdown&quot;) You can&#39;t explain why this cause occurred Output: Visual causal chain from symptom to root cause. C - Challenge Assumptions Every investigation is built on assumptions. Some are valid. Some aren&#39;t. Questions to ask: What are we assuming to be true without evidence? What if the opposite were true? Whose perspective are we missing? What evidence would contradict our current hypothesis? Common hidden assumptions: &quot;The process is being followed as documented&quot; &quot;The people involved are telling us everything&quot; &quot;The metric we&#39;re measuring reflects the real problem&quot; &quot;Past performance predicts future behavior&quot; Output: List of validated and invalidated assumptions. E - Expose the Root The root cause is the deepest point in the causal chain where intervention is both possible and effective. Root cause criteria: Removing it prevents recurrence It&#39;s within the organization&#39;s control Addressing it is proportional to the problem The evidence supports it Validation tests: If this was the root cause, would this symptom have occurred? (Yes) If we eliminate this cause, will the symptom recur? (No) Can we trace the causal chain from this cause to the symptom? (Yes) Is there a deeper cause we haven&#39;t explored? (No) Output: Documented root cause with supporting evidence. Putting It Together TRACE is iterative. You&#39;ll often cycle back through earlier phases as new information emerges: Start: Target the symptom Gather: Record initial evidence Map: Begin analyzing the chain Test: Challenge emerging hypotheses Refine: Return to evidence gathering with new questions Converge: Expose the root when evidence supports it When to Use TRACE Complex problems with unclear causes Recurring problems that resist simple fixes High-stakes situations where being wrong is costly Situations where multiple stakeholders have different explanations When TRACE is Overkill Simple problems with obvious causes Situations where speed matters more than certainty Problems where the solution is known and implementation is the challenge TRACE provides structure, not a script. Adapt it to your context. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"The TRACE Protocol TRACE is our systematic approach to diagnostic investigation. It provides structure without being prescriptive, ensuring thorough investigation while remaining adaptable to different problem types. The Framework T - Target the Symptom Before you can solve a problem, you need to define it precisely. Questions to answer: What exactly is happening? What should be happening instead? What is the gap between current and desired state? How do we measure the symptom? Common mistakes: ","category":"Wiki"},{"url":"wiki/getting-started.html","title":"Getting Started with Fogsift","description":"Welcome to the Fogsift knowledge base. This wiki contains documentation, concepts, frameworks, and field notes from our consulting work.","headings":["Getting Started with Fogsift Welcome to the Fogsift knowledge base. This wiki contains documentation, concepts, frameworks, and field notes from our consulting work. What is Fogsift? Fogsift provides independent consulting for complex, ambiguous problems. We specialize in: Root Cause Analysis : Tracing symptoms back to their source System Diagnostics : Understanding how components interact Strategic Clarity : Cutting through organizational fog How to Use This Wiki Documentation Practical guides and how-to content. Start here if you want to understand our methods. Getting Started - You are here How We Work - Our approach and engagement types The Diagnostic Process - Step-by-step investigation method FAQ - Frequently asked questions Concepts Deep dives into the mental models and ideas that inform our work. Root Cause Analysis - Finding the source, not the symptom Mental Models - Frameworks for understanding reality Systems Thinking - Seeing interconnections Cognitive Biases - Thinking traps to avoid Second-Order Effects - Consequences of consequences Signal vs Noise - Finding meaning in data Frameworks Structured approaches for common diagnostic challenges. The TRACE Protocol - Our systematic investigation method Decision Matrix - Evaluating options objectively Constraint Mapping - Understanding what limits solutions Feedback Loop Analysis - Finding circular causation Field Notes Real observations from client engagements (anonymized). Raw insights from the field. The Map Is Not The Territory - Org charts vs reality Precision vs Accuracy - Different problems, different fixes Entropy - Chaos is the default Finding the Bottleneck - Where to focus improvement Tribal Knowledge - The danger of undocumented expertise Incentive Alignment - Behavior follows rewards Documentation Debt - The cost of not writing things down Case Studies In-depth examples of diagnostic engagements (anonymized). Manufacturing Throughput Crisis - Finding the invisible bottleneck The Communication Breakdown - Scaling organizational infrastructure The Invisible Process - Making hidden work visible Tools &amp; Techniques Specific methods for investigation and analysis. The Five Whys - Drilling to root cause Fishbone Diagrams - Mapping possible causes Pareto Analysis - Finding the vital few Process Mapping - Visualizing how work flows Where to Start New to diagnostic thinking? Start with Mental Models , then read the Field Notes for practical examples. Have a specific problem? Look at The Diagnostic Process and the TRACE Protocol . Want to learn tools? Start with The Five Whys and Process Mapping . Need Help? If you have a weird question that doesn&#39;t fit in a standard box, use the Weird Question Hotline . Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Getting Started with Fogsift Welcome to the Fogsift knowledge base. This wiki contains documentation, concepts, frameworks, and field notes from our consulting work. What is Fogsift? Fogsift provides independent consulting for complex, ambiguous problems. We specialize in: Root Cause Analysis : Tracing symptoms back to their source System Diagnostics : Understanding how components interact Strategic Clarity : Cutting through organizational fog How to Use This Wiki Documentation Practical guides ","category":"Wiki"},{"url":"wiki/how-we-work.html","title":"How We Work","description":"Fogsift operates differently from traditional consulting. We don't bring pre-packaged solutions. We bring diagnostic capability.","headings":["How We Work Fogsift operates differently from traditional consulting. We don&#39;t bring pre-packaged solutions. We bring diagnostic capability. The Approach We Listen First Most problems are explained wrong. Not because people are bad at explaining, but because the symptoms they&#39;re experiencing aren&#39;t the actual problem. We spend the first part of any engagement just listening, asking questions, and mapping the terrain. We Follow the Evidence We don&#39;t have favorite solutions. We don&#39;t push frameworks. We trace the wires from symptom to source, and we let the evidence tell us where to look next. We Transfer Knowledge Our goal is to make ourselves unnecessary. Every engagement includes knowledge transfer so your team can maintain and extend the solutions we develop together. Engagement Types Diagnostic Sessions Duration: 2-4 hours Format: Intensive Q&amp;A and analysis Output: Written diagnosis with recommendations Best for: Specific problems where you need an outside perspective. Deep Dives Duration: 1-2 weeks Format: Embedded investigation Output: Root cause analysis with implementation roadmap Best for: Complex, systemic issues that require thorough investigation. Retainer Duration: Ongoing Format: On-call access with monthly check-ins Output: Continuous advisory support Best for: Organizations that need ongoing access to diagnostic expertise. What We Don&#39;t Do We don&#39;t do the work for you (we help you understand what work to do) We don&#39;t provide &quot;best practices&quot; without context We don&#39;t pretend to know your business better than you do We don&#39;t sell solutions looking for problems Ready to Start? The first conversation is free. We&#39;ll talk about what&#39;s going on, and if it&#39;s something we can help with, we&#39;ll figure out the right format together. Get in touch Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"How We Work Fogsift operates differently from traditional consulting. We don&#39;t bring pre-packaged solutions. We bring diagnostic capability. The Approach We Listen First Most problems are explained wrong. Not because people are bad at explaining, but because the symptoms they&#39;re experiencing aren&#39;t the actual problem. We spend the first part of any engagement just listening, asking questions, and mapping the terrain. We Follow the Evidence We don&#39;t have favorite solutions. We don","category":"Wiki"},{"url":"wiki/index.html","title":"Wiki","description":"Fogsift knowledge base - documentation, concepts, and field notes from our consulting work.","headings":[],"content":"","category":"Wiki"},{"url":"wiki/tools/fishbone-diagram.html","title":"Fishbone Diagrams","description":"A fishbone diagram (also called Ishikawa or cause-and-effect diagram) visually maps the potential causes of a problem. It's particularly useful when multiple fa","headings":["Fishbone Diagrams A fishbone diagram (also called Ishikawa or cause-and-effect diagram) visually maps the potential causes of a problem. It&#39;s particularly useful when multiple factors might contribute and you need to systematically explore possibilities. The Structure ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ Category 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ ‚îÇ Cause 1.1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ Cause 1.2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ PROBLEM ‚îÇ ‚îÇ ‚îÇ Category 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ Cause 2.1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ Cause 2.2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò The &quot;head&quot; of the fish is the problem. The &quot;bones&quot; are categories of potential causes. Smaller bones are specific causes within each category. Building the Diagram Step 1: Define the Problem Write the problem clearly at the head of the fish. Be specific. &quot;Customer complaints&quot; is too vague. &quot;Customers complaining about delivery time&quot; is better. Step 2: Choose Categories Draw major bones for each category of causes. Common category sets: Manufacturing (6 Ms): Man (People) Machine (Equipment) Method (Process) Material (Inputs) Measurement Mother Nature (Environment) Services (8 Ps): Price Promotion People Processes Place/Plant Policies Procedures Product Or create your own: Systems People Process External (Whatever fits your context) Step 3: Brainstorm Causes For each category, brainstorm potential causes. Add them as smaller bones. Don&#39;t evaluate yet, just collect. Step 4: Dig Deeper For each cause, ask &quot;why?&quot; Add sub-causes as even smaller bones. This is where the Five Whys technique combines with fishbone diagrams. Step 5: Analyze Look for: Causes that appear in multiple categories Clusters of related causes Causes with strong evidence Causes that are actionable Step 6: Prioritize Not all causes are equal. Use evidence and judgment to identify the most likely root causes. Investigate those first. Example Problem: High employee turnover Category Causes People Poor hiring fit, Inadequate onboarding, Manager quality, Team dynamics Process Unclear expectations, No career path, Slow decision-making, Too much bureaucracy Compensation Below market salary, Unclear bonus structure, Limited benefits, No equity Culture Toxic behaviors tolerated, No recognition, Work-life imbalance, Lack of purpose Environment Poor tools, Office location, Remote policy, Physical workspace External Competitor recruiting, Industry trends, Economy, Geographic factors After investigation, you might find the primary drivers are &quot;Manager quality&quot; and &quot;No career path,&quot; with &quot;Below market salary&quot; as a contributing factor. When to Use It Complex problems with multiple potential causes Group brainstorming sessions When you need to ensure comprehensive analysis When different stakeholders have different theories Teaching teams to think systematically about causation When It Doesn&#39;t Work Too Many Causes If you generate 50 causes, the diagram becomes unwieldy. Prioritize or group similar causes. No Investigation Fishbone diagrams generate hypotheses. They don&#39;t prove anything. Each suspected cause needs verification. Consensus Theater Sometimes teams use fishbone diagrams to create false agreement. Everyone&#39;s theory goes on the diagram, but no one&#39;s theory gets tested. Linear Problems If the cause is straightforward, a fishbone diagram is overkill. Use Five Whys instead. Best Practices Use in Groups Fishbone diagrams work best as group exercises. Different perspectives surface different causes. Be Specific &quot;Communication problems&quot; is too vague. &quot;Status updates not reaching stakeholders&quot; is better. Include Data Where possible, attach evidence to causes. &quot;Manager quality&quot; backed by &quot;Exit interviews cite manager in 60% of departures&quot; is more persuasive. Iterate The first pass is rarely complete. Revisit after investigation. Add what you&#39;ve learned. Remove what&#39;s been ruled out. Avoid Blame Keep the focus on systems and processes, not individuals. &quot;John&#39;s errors&quot; isn&#39;t useful. &quot;Inadequate training for complex tasks&quot; is useful. Combining with Other Tools Five Whys: For each bone, ask why to find deeper causes Pareto Analysis: Prioritize which causes to address first TRACE Protocol: Use the fishbone in the &quot;Analyze&quot; phase A fishbone diagram doesn&#39;t solve the problem. It maps the territory where the solution lives. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Fishbone Diagrams A fishbone diagram (also called Ishikawa or cause-and-effect diagram) visually maps the potential causes of a problem. It&#39;s particularly useful when multiple factors might contribute and you need to systematically explore possibilities. The Structure ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ Category 1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ ‚îÇ Cause 1.1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ Cause 1.2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ PROBLEM ‚îÇ ‚îÇ ‚îÇ Category 2 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ C","category":"Wiki"},{"url":"wiki/tools/five-whys.html","title":"The Five Whys","description":"The Five Whys is a simple but powerful technique for drilling past symptoms to find root causes. Ask ","headings":["The Five Whys The Five Whys is a simple but powerful technique for drilling past symptoms to find root causes. Ask &quot;why?&quot; repeatedly until you reach a cause you can actually address. The Method Start with a problem statement Ask &quot;Why did this happen?&quot; Take the answer and ask &quot;Why?&quot; again Repeat until you reach an actionable root cause (Usually takes about five iterations, hence the name) Example Problem: The website went down during peak traffic Why? The server ran out of memory Why? The application had a memory leak Why? Database connections weren&#39;t being closed Why? The connection pooling configuration was wrong Why? We used default settings from a tutorial without understanding them Root cause: Configuration wasn&#39;t reviewed for production requirements Action: Create a deployment checklist that includes configuration review When to Use It Initial investigation of problems When you need to move quickly from symptom to cause When the causal chain is relatively linear As a facilitation technique in group problem-solving When It Doesn&#39;t Work Complex Causation When multiple causes interact, asking &quot;why?&quot; in a straight line misses the complexity. You might need Fishbone Diagrams or systems mapping instead. Human-Caused Problems &quot;Why?&quot; can feel like blame. &quot;Why did you make that mistake?&quot; puts people on the defensive. Rephrase: &quot;What about the situation led to this outcome?&quot; Inadequate Expertise If no one in the room understands the system, asking &quot;why?&quot; just generates guesses. You need investigation, not interrogation. Premature Termination People often stop at convenient answers. &quot;Human error&quot; is not a root cause. Neither is &quot;didn&#39;t follow the process.&quot; Ask why those things happened. Best Practices Keep Asking Five is a guideline, not a rule. Sometimes you need three whys. Sometimes you need seven. Stop when you reach something actionable. Verify Each Answer Each &quot;because&quot; should be factual, not hypothetical. If you don&#39;t know, investigate before proceeding. Consider Multiple Branches The first &quot;why&quot; might have multiple answers. Explore each branch. The real root cause might be in an unexpected direction. Focus on Systems, Not People &quot;John made an error&quot; is not useful. &quot;The system allowed/encouraged John&#39;s error&quot; is useful. Document the Chain Write down each why and because. This creates a record and makes gaps visible. Variations 5 Whys with Evidence For each &quot;because,&quot; require supporting evidence. Slows down the process but increases accuracy. Branching 5 Whys When you get multiple answers to a &quot;why,&quot; explore each branch separately. Results in a tree rather than a line. 5 Whys + 2 Hows After finding the root cause, ask &quot;How do we prevent this?&quot; and &quot;How do we detect it earlier?&quot; Common Mistakes Stopping at Symptoms &quot;Why did the server crash?&quot; ‚Üí &quot;Because it was overloaded.&quot; That&#39;s still a symptom. Keep going. Accepting &quot;Because X Failed to Y&quot; &quot;Because QA failed to catch the bug&quot; blames QA without asking why the bug was catchable and wasn&#39;t caught. Guessing &quot;I think it&#39;s because...&quot; is a hypothesis. Verify it before treating it as fact. Single Path Taking only the first answer at each level. Reality is often multi-causal. The Deeper Point The Five Whys isn&#39;t really about the number five. It&#39;s about: Not accepting the obvious answer. The first explanation is usually incomplete. Tracing causation systematically. Following the chain rather than jumping to conclusions. Finding actionable causes. Stopping at something you can actually change. The first answer is rarely the root cause. Keep asking. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"The Five Whys The Five Whys is a simple but powerful technique for drilling past symptoms to find root causes. Ask &quot;why?&quot; repeatedly until you reach a cause you can actually address. The Method Start with a problem statement Ask &quot;Why did this happen?&quot; Take the answer and ask &quot;Why?&quot; again Repeat until you reach an actionable root cause (Usually takes about five iterations, hence the name) Example Problem: The website went down during peak traffic Why? The server ran ","category":"Wiki"},{"url":"wiki/tools/pareto-analysis.html","title":"Pareto Analysis","description":"Pareto Analysis applies the 80/20 rule to problem-solving: roughly 80% of effects come from 20% of causes. By identifying and focusing on the vital few, you get","headings":["Pareto Analysis Pareto Analysis applies the 80/20 rule to problem-solving: roughly 80% of effects come from 20% of causes. By identifying and focusing on the vital few, you get maximum impact from limited resources. The Principle Not all causes are equal. A few critical causes typically account for most of the problem. Finding those causes and addressing them first is more effective than treating everything equally. Examples: 80% of complaints come from 20% of issues 80% of defects come from 20% of root causes 80% of delays come from 20% of bottlenecks 80% of value comes from 20% of effort The specific ratio varies. It might be 70/30 or 90/10. The point is that impact is unequally distributed. Building a Pareto Chart Step 1: Define the Problem What are you analyzing? Defect types? Complaint categories? Delay reasons? Be specific. Step 2: Collect Data Count occurrences by category. You need frequency data. Issue Type Count Late delivery 85 Wrong item 42 Damaged item 28 Billing error 15 Missing item 12 Other 8 Step 3: Calculate Percentages Convert counts to percentages of total. Issue Type Count Percentage Late delivery 85 45% Wrong item 42 22% Damaged item 28 15% Billing error 15 8% Missing item 12 6% Other 8 4% Step 4: Calculate Cumulative Percentage Add up percentages as you go down the list. Issue Type Count Percentage Cumulative Late delivery 85 45% 45% Wrong item 42 22% 67% Damaged item 28 15% 82% Billing error 15 8% 90% Missing item 12 6% 96% Other 8 4% 100% Step 5: Identify the Vital Few Look for where cumulative percentage crosses 80%. In this example, &quot;Late delivery&quot; and &quot;Wrong item&quot; account for 67% of issues. Adding &quot;Damaged item&quot; gets to 82%. These three categories are the vital few. Step 6: Focus Resources Address the vital few first. Solving late delivery alone eliminates nearly half the complaints. When to Use It Resource allocation decisions Prioritizing improvement efforts Focusing investigation on high-impact areas Communicating priorities to stakeholders Quality improvement programs When It Doesn&#39;t Work Uniform Distribution If issues are evenly distributed across categories, there&#39;s no vital few. All causes need attention. Critical Low-Frequency Events Some rare events are catastrophic. A safety failure that happens 1% of the time might matter more than a convenience issue that happens 50% of the time. Pareto analysis counts frequency, not severity. Changing Patterns If the distribution shifts over time, a static Pareto analysis becomes misleading. Update regularly. Category Bias How you define categories affects results. &quot;Late delivery&quot; might hide multiple root causes that should be separated. Best Practices Weight by Impact If different issues have different costs or severity, multiply frequency by impact before calculating percentages. Issue Count Cost Each Total Cost Billing error 15 $500 $7,500 Late delivery 85 $50 $4,250 Wrong item 42 $100 $4,200 Now billing errors might be the top priority despite lower frequency. Drill Down Once you identify the vital few, apply Pareto analysis within each category. &quot;Late delivery&quot; might break down into subcauses, one of which accounts for most late deliveries. Track Over Time After addressing top causes, the Pareto shifts. The next tier becomes the new vital few. Continuous improvement means continuously updating your analysis. Use With Other Tools Pareto tells you what to focus on. Other tools tell you why it happens: Use Pareto to prioritize Use Fishbone diagrams to explore causes Use Five Whys to find root causes Use Process mapping to understand the system Common Mistakes Cherry-Picking Data Selecting time periods or data sources that support a preferred conclusion. Ignoring the Vital Many After fixing the vital few, don&#39;t ignore the rest forever. At some point, the remaining 20% of causes become significant. Category Manipulation Splitting or combining categories to change the analysis. Be consistent and transparent. Static Analysis Doing Pareto once and never updating it as conditions change. The Deeper Point Pareto analysis is about focus. In a world of unlimited resources, treat everything equally. In reality, resources are limited. Pareto helps you invest where it matters most. Not all causes are equal. Find the few that matter. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Pareto Analysis Pareto Analysis applies the 80/20 rule to problem-solving: roughly 80% of effects come from 20% of causes. By identifying and focusing on the vital few, you get maximum impact from limited resources. The Principle Not all causes are equal. A few critical causes typically account for most of the problem. Finding those causes and addressing them first is more effective than treating everything equally. Examples: 80% of complaints come from 20% of issues 80% of defects come from 20%","category":"Wiki"},{"url":"wiki/tools/process-mapping.html","title":"Process Mapping","description":"Process mapping creates a visual representation of how work flows through a system. It reveals gaps, redundancies, bottlenecks, and opportunities for improvemen","headings":["Process Mapping Process mapping creates a visual representation of how work flows through a system. It reveals gaps, redundancies, bottlenecks, and opportunities for improvement that are invisible in verbal descriptions. Why Map Processes? Reality vs. Perception The process people describe is rarely the process they follow. Mapping reveals the actual flow. Hidden Complexity Simple processes often have hidden steps, decision points, and exceptions. Mapping makes them visible. Communication A visual map communicates more clearly than paragraphs of text. Different stakeholders can literally point to where they see problems. Baseline for Improvement You can&#39;t improve what you don&#39;t understand. Maps create the foundation for optimization. Types of Process Maps Flowchart Basic steps and decision points. Good for simple, linear processes. [Start] ‚Üí [Step 1] ‚Üí [Decision?] ‚Üí [Step 2A] ‚Üí [End] ‚Üì [Step 2B] ‚Üí [End] Swimlane Diagram Shows who performs each step. Good for cross-functional processes. ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Customer ‚îÇ [Request] ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ Sales ‚îÇ ‚îÇ [Quote] ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ Operations ‚îÇ ‚îÇ [Fulfill] ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò Value Stream Map Shows time, value-add vs. waste, and inventory between steps. Good for lean improvement. SIPOC High-level view: Suppliers, Inputs, Process, Outputs, Customers. Good for scoping before detailed mapping. Building a Process Map Step 1: Define Scope Where does the process start? Where does it end? What&#39;s in scope? Common boundaries: When a request arrives ‚Üí when it&#39;s fulfilled When a problem is detected ‚Üí when it&#39;s resolved When material arrives ‚Üí when product ships Step 2: Identify Steps Walk through the process. Document each action. Methods: Observe the process in action Interview people who do the work Review existing documentation (skeptically) Follow a specific case through the system Step 3: Sequence Steps Arrange steps in order. Identify parallel paths and decision points. Step 4: Add Detail For each step, capture: Who performs it How long it takes What inputs are needed What outputs are produced What can go wrong Step 5: Validate Review the map with people who do the work. They&#39;ll catch errors and omissions. Step 6: Analyze Look for: Bottlenecks: Where does work queue up? Loops: Where do things go back for rework? Handoffs: Where does work transfer between people/teams? Decision points: Where does the process branch? Delays: Where does work wait? Redundancy: Where is work duplicated? Missing steps: What happens that isn&#39;t documented? What to Look For Non-Value-Add Steps Steps that don&#39;t contribute to what the customer values. Transport, waiting, inspection, rework. Exception Handling How are unusual cases handled? Are there undocumented workarounds? Information Gaps Where do people lack information they need? Where do they hunt for data? Approval Bottlenecks Where do approvals slow things down? Are all those approvals necessary? Handoff Failures Where does work fall through cracks between teams or shifts? Best Practices Map What Is, Not What Should Be Document the current reality, including workarounds and exceptions. Improvement comes later. Include the Informal The unofficial steps, the shortcuts, the tribal knowledge: these are often more important than formal procedures. Use Consistent Symbols Standard symbols make maps readable: Rectangles: Steps Diamonds: Decisions Arrows: Flow direction Ovals: Start/End Circles: Connectors Keep It Readable A map that&#39;s too detailed becomes useless. Create high-level overviews, then drill down where needed. Date and Version Processes change. Mark when the map was made and what version it is. Common Mistakes Mapping the Ideal Drawing how the process should work instead of how it does work. Over-Detailing Trying to capture every possible exception and edge case. The map becomes unreadable. Skipping Validation Assuming you understood correctly without checking with the people who do the work. One-Time Exercise Treating mapping as a project rather than a living document. Processes evolve; maps should too. Ignoring Variation Mapping one version of a process when multiple versions exist. Different shifts, different sites, different people might follow different processes. Using the Map Once you have a process map: Identify improvements: Where are the obvious waste and delay? Prioritize: Which improvements have the biggest impact? See Pareto Analysis . Design future state: Map how you want the process to work. Plan transition: What needs to change to get from current to future? Implement and measure: Make changes, measure results. Update the map: The new current state becomes the new baseline. You can&#39;t improve what you can&#39;t see. Mapping makes the invisible visible. Updated: 2026-02-07 &larr; Back to Wiki Sitemap 10-19 Documentation 10.01 Getting Started 10.02 How We Work 10.03 The Diagnostic Process 10.04 Frequently Asked Questions 20-29 Concepts 20.01 Root Cause Analysis 20.02 Mental Models 20.03 Systems Thinking 20.04 Cognitive Biases 20.05 Second-Order Effects 20.06 Signal vs Noise 30-39 Frameworks 30.01 The TRACE Protocol 30.02 Decision Matrix 30.03 Constraint Mapping 30.04 Feedback Loop Analysis 40-49 Field Notes 40.01 The Map Is Not The Territory 40.02 Precision vs Accuracy 40.03 Entropy 40.04 Finding the Bottleneck 40.05 Tribal Knowledge 40.06 Incentive Alignment 40.07 Documentation Debt 50-59 Case Studies 50.01 Manufacturing Throughput Crisis 50.02 The Communication Breakdown 50.03 The Invisible Process 60-69 Tools & Techniques"],"content":"Process Mapping Process mapping creates a visual representation of how work flows through a system. It reveals gaps, redundancies, bottlenecks, and opportunities for improvement that are invisible in verbal descriptions. Why Map Processes? Reality vs. Perception The process people describe is rarely the process they follow. Mapping reveals the actual flow. Hidden Complexity Simple processes often have hidden steps, decision points, and exceptions. Mapping makes them visible. Communication A visu","category":"Wiki"}]