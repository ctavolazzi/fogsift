# Confirmation Bias

*We don't seek information. We seek confirmation.*

---

## The Principle

Confirmation bias is the tendency to search for, interpret, and recall information in a way that confirms existing beliefs or hypotheses — while giving insufficient attention to information that contradicts them.

It's the most pervasive and consequential cognitive bias in decision-making. Unlike many biases that affect edge cases, confirmation bias operates continuously, shaping what we notice, what we remember, and what we conclude from ambiguous evidence.

The original concept was formalized by Peter Wason through his 2-4-6 task experiment (1960): participants given a sequence of numbers and asked to identify the rule almost universally tested only examples that fit their hypothesized rule — never tested disconfirming examples — and reached wrong conclusions while feeling confident.

---

## Three Forms

**Biased information search.** When we look for evidence, we disproportionately seek sources that will confirm what we believe. A manager who suspects an employee is underperforming notices the failures and ignores the successes. A market researcher who believes a product will succeed focuses on positive signals.

**Biased interpretation.** Ambiguous evidence gets interpreted through the lens of existing beliefs. The same data can be read as confirming opposite conclusions by people with different priors. Studies on strongly-held topics (diet, politics, business strategy) show that people exposed to identical mixed evidence come away more polarized, not less.

**Biased memory.** People selectively recall information that confirms their beliefs. Over time, memory of conflicting information fades while confirming memories are reinforced. This makes people increasingly confident over time even as their evidence base gets less accurate.

---

## Why It Persists

Confirmation bias has evolutionary roots: fast pattern-recognition and commitment to action had survival value. A correct hypothesis that gets you out of danger is more useful than an exhaustive survey of evidence that gets you killed.

In modern organizational contexts, this reasoning doesn't hold. The problems it causes:

- **Bad decisions held confidently.** People feel most certain precisely when they've engaged in the most motivated reasoning.
- **Resistant to correction.** Because new evidence is filtered through existing beliefs, correction is slow. The stronger the initial belief, the more resistant it is to evidence.
- **Amplified by group dynamics.** Groups become echo chambers. People self-select into teams that share their priors. Dissent is socially costly. Groupthink is confirmation bias at the institutional level.

---

## Organizational Examples

**Strategy confirmation.** A company's leadership believes a market is growing. They commission research. The research team, knowing what the answer "should" be, finds confirming evidence. Contradictory signals are explained away. The strategic failure that follows isn't lack of data — it's biased processing of abundant data.

**Hiring.** First impressions of candidates drive subsequent interview questioning. Interviewers who form a positive early impression ask questions that elicit confirming responses. Structured interviews exist specifically to counteract this.

**Performance reviews.** Early impressions of employees shape the evidence managers subsequently notice. An employee who makes a strong first impression accumulates confirming evidence over time; an employee who makes a weak one does the same.

**Customer research.** User research conducted by product teams with strong opinions systematically overweights positive responses and explains away negative ones. "They didn't understand the feature" becomes a way to dismiss criticism.

**Due diligence.** Investors and acquirers who have formed a thesis about a deal conduct due diligence that confirms it. Red flags are noticed but downweighted; confirming signals are weighted heavily.

---

## The Diagnostic Question

*If my current belief were wrong, what would I expect to see?*

Then: *Have I specifically looked for that evidence?*

If the answer to the second question is no — if you've been building your case rather than testing it — you're operating in confirmation bias territory.

---

## Mitigations

**Steelman the opposition.** Before dismissing a contrary view, state the strongest version of the case against your position. If you can't steelman it, you don't understand the disagreement well enough to dismiss it.

**Pre-mortem for beliefs.** Apply pre-mortem logic to decisions: "Assume this belief is wrong. What would have caused me to hold it anyway?" This surfaces the motivated reasoning.

**Structured devil's advocate.** Assign someone to argue the contrary case before decisions are made. This has to be structured — spontaneous dissent is suppressed by group dynamics. Assign the role explicitly.

**Seek disconfirming data first.** Before looking at evidence that confirms a hypothesis, deliberately seek evidence that would falsify it. This inverts the default tendency.

**Separate evidence from interpretation.** Document what you actually observed vs. what you infer from it. Evidence: "Customer said 'I'm not sure I'd use this.'" Interpretation: "They're unsure." Without the separation, interpretation contaminates memory of evidence.

**Quantify beliefs.** Expressing beliefs as probabilities ("I think there's a 70% chance this will work") makes updating easier. It's harder to cling to a specific estimate than to a vague sense of confidence.

---

## Confirmation Bias and Expertise

More expertise does not reduce confirmation bias — and in some cases amplifies it. Experts have more developed frameworks for interpreting evidence, which means they're better at explaining away contradictions while feeling rigorous.

This is why expert consensus can be wrong for decades on questions where the data is mixed. The confirmation bias is operating at a higher level of sophistication, but it's still operating.

---

## Related Concepts

**Motivated reasoning:** A related but distinct concept. Confirmation bias can be unconscious; motivated reasoning involves conscious or semi-conscious distortion of reasoning toward a desired conclusion.

**Backfire effect:** The (contested) finding that correcting misconceptions can strengthen them when they're tied to identity. Strong form is disputed, but belief-protective motivated reasoning is real.

**Echo chambers:** The social and institutional amplification of confirmation bias, where information environments are structured to minimize exposure to disconfirming views.

---

*Related: [Cognitive Biases](./cognitive-biases.html), [Survivorship Bias](./survivorship-bias.html), [Signal vs Noise](./signal-vs-noise.html), [Pre-Mortem Analysis](../frameworks/pre-mortem.html)*
